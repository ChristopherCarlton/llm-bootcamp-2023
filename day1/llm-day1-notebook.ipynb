{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite: Run the following commands in a terminal window to create a conda environment.\n",
    "\n",
    "<pre>\n",
    "- conda create --name llm-bootcamp -c https://repo.anaconda.com/pkgs/snowflake python=3.9\n",
    "- conda activate llm-bootcamp\n",
    "- conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python pandas notebook\n",
    "<pre/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-ml-python==1.0.12\n",
      "  Downloading snowflake_ml_python-1.0.12-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting absl-py<2,>=0.15 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (3.5.0)\n",
      "Collecting cachetools<5,>=3.1.1 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.0.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (2.0.0)\n",
      "Collecting fsspec<2024,>=2022.11 (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading fsspec-2023.12.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting importlib_resources<6,>=5.1.4 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading importlib_resources-5.13.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (1.26.0)\n",
      "Requirement already satisfied: packaging<24,>=20.9 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (23.1)\n",
      "Collecting pandas<2,>=1.0.0 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytimeparse<2,>=1.1.8 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=6.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (6.0.1)\n",
      "Collecting s3fs<2024,>=2022.11 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading s3fs-2023.12.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting scikit-learn<1.4,>=1.2.1 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading scikit_learn-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy<2,>=1.9 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading scipy-1.11.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: snowflake-connector-python<4,>=3.0.4 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.2.0)\n",
      "Requirement already satisfied: snowflake-snowpark-python<2,>=1.5.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (1.9.0)\n",
      "Collecting sqlparse<1,>=0.4 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.1.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-ml-python==1.0.12) (4.7.1)\n",
      "Collecting xgboost<2,>=1.7.3 (from snowflake-ml-python==1.0.12)\n",
      "  Downloading xgboost-1.7.6-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.0.12) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.0.12) (1.2.0)\n",
      "Requirement already satisfied: requests in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (2.31.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading aiohttp-3.9.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from importlib_resources<6,>=5.1.4->snowflake-ml-python==1.0.12) (3.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (2.8.3+snowflake1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (2023.3.post1)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading aiobotocore-2.8.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn<1.4,>=1.2.1->snowflake-ml-python==1.0.12)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.4,>=1.2.1->snowflake-ml-python==1.0.12)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.15.1)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (41.0.3)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.2.1)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (23.2.0)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.15.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2023.7.22)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<3.9.0,>=2.6.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.8.1)\n",
      "Requirement already satisfied: tomlkit in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (0.11.1)\n",
      "Requirement already satisfied: pyarrow<10.1.0,>=10.0.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (10.0.1)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-snowpark-python<2,>=1.5.1->snowflake-ml-python==1.0.12) (68.0.0)\n",
      "Requirement already satisfied: wheel in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from snowflake-snowpark-python<2,>=1.5.1->snowflake-ml-python==1.0.12) (0.41.2)\n",
      "Collecting botocore<1.33.2,>=1.32.4 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading botocore-1.33.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pycparser in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4,>=3.0.4->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (1.16.0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.33.2,>=1.32.4->aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading snowflake_ml_python-1.0.12-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-5.13.0-py3-none-any.whl (32 kB)\n",
      "Downloading s3fs-2023.12.1-py3-none-any.whl (28 kB)\n",
      "Downloading scikit_learn-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp39-cp39-macosx_10_9_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-1.7.6-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiobotocore-2.8.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp39-cp39-macosx_10_9_x86_64.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.9/397.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading botocore-1.33.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (37 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytimeparse, wrapt, threadpoolctl, sqlparse, scipy, multidict, joblib, jmespath, importlib_resources, fsspec, frozenlist, cachetools, async-timeout, aioitertools, absl-py, yarl, xgboost, scikit-learn, pandas, botocore, aiosignal, aiohttp, aiobotocore, s3fs, snowflake-ml-python\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "Successfully installed absl-py-1.4.0 aiobotocore-2.8.0 aiohttp-3.9.1 aioitertools-0.11.0 aiosignal-1.3.1 async-timeout-4.0.3 botocore-1.33.1 cachetools-4.2.4 frozenlist-1.4.0 fsspec-2023.12.1 importlib_resources-5.13.0 jmespath-1.0.1 joblib-1.3.2 multidict-6.0.4 pandas-1.5.3 pytimeparse-1.1.8 s3fs-2023.12.1 scikit-learn-1.3.2 scipy-1.11.4 snowflake-ml-python-1.0.12 sqlparse-0.4.4 threadpoolctl-3.2.0 wrapt-1.16.0 xgboost-1.7.6 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-ml-python==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.34.0\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.15.0-cp39-cp39-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from transformers==4.34.0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from transformers==4.34.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from transformers==4.34.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from transformers==4.34.0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.34.0)\n",
      "  Downloading regex-2023.10.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from transformers==4.34.0) (2.31.0)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.34.0)\n",
      "  Downloading safetensors-0.4.1-cp39-cp39-macosx_10_7_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.34.0)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (2023.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from requests->transformers==4.34.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from requests->transformers==4.34.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from requests->transformers==4.34.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages (from requests->transformers==4.34.0) (2023.7.22)\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp39-cp39-macosx_10_7_x86_64.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.6/441.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.17.3 regex-2023.10.3 safetensors-0.4.1 tokenizers-0.14.1 tqdm-4.66.1 transformers-4.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.34.0 tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.model.models import llm\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection\n",
    "\n",
    "*NOTE: Update [connection.json](connection.json) and set your password, Hugging Face token, and replace '####' with your user number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : USER0007\n",
      "Role                        : \"ROLE_USER0007\"\n",
      "Database                    : \"DB_USER0007\"\n",
      "Schema                      : \"SCHEMA_LLM\"\n",
      "Warehouse                   : \"WH_XS_USER0007\"\n",
      "Snowflake version           : 7.43.0\n",
      "Snowpark for Python version : 1.9.0\n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Llama 2 from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Downloading config.json: 100%|██████████| 614/614 [00:00<00:00, 83.1kB/s]\n"
     ]
    }
   ],
   "source": [
    "options = llm.LLMOptions(\n",
    "    token=connection_parameters['huggingface_token'],\n",
    "    max_batch_size=100,\n",
    ")\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register, Log and Deploy Llama 2 into Snowpark Container Services \n",
    "\n",
    "*NOTE: Logging and deploying the same model are one time operations. Once the model is logged and deployed, use ModeReference to get the reference to the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_model_registry() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:absl:The database DB_USER0007 already exists. Skipping creation.\n",
      "WARNING:absl:The schema DB_USER0007.SCHEMA_LLM already exists. Skipping creation.\n",
      "WARNING:snowflake.snowpark:ModelRegistry.log_model() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.list_models() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME    = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"NewBaseV2.0\"\n",
    "MODEL_REGISTRY_DB = connection_parameters['database']\n",
    "MODEL_REGISTRY_SCHEMA = connection_parameters['schema']\n",
    "COMPUTE_POOL = connection_parameters['compute_pool']\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MODEL_REGISTRY_DB, \n",
    "    schema_name=MODEL_REGISTRY_SCHEMA, \n",
    "    create_if_not_exists=True)\n",
    "\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Deploying model for the first time can take ~25-30mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.deploy() is in private preview since 0.2.0. Do not use it in production. \n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DB_USER0007.SCHEMA_LLM]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE STAGE IF NOT EXISTS DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_DEPLOYMENTS_S...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VI...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [LIST @DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_6F58D2DE947F11EEB19FACDE48001122]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VI...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [ls @DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_6F58D2DE947F11EEB19FACDE48001122]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_6F58D2DE947F11EEB19FACDE48001122/model...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "/Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages/snowflake/ml/model/_packager/model_env/model_env.py:353: UserWarning: Found dependencies specified as pip requirements. This may prevent model deploying to Snowflake Warehouse.\n",
      "  warnings.warn(\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy_options:num_workers has been defaulted to 1 when using GPU.\n",
      "WARNING:snowflake.ml.model._deploy_client.snowservice.deploy:Building the Docker image and deploying to Snowpark Container Service. This process may take anywhere from a few minutes to a longer period for GPU-based models.\n",
      "INFO:snowflake.ml.model._deploy_client.image_builds.server_image_builder:Starting server-side image build\n",
      "INFO:snowflake.ml.model._deploy_client.utils.image_registry_client:Copying image from gcr.io/kaniko-project/executor@sha256:b8c0977f88f24dbd7cbc2ffe5c5f824c410ccd0952a72cc066efc4b6dfbb52b6 to sfsenorthamerica-build-spcs4.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/kaniko-project/executor:v1.16.0-debug\n",
      "INFO:snowflake.ml.model._deploy_client.utils.image_registry_client:Image copy completed successfully\n",
      "WARNING:snowflake.ml.model._deploy_client.utils.snowservice_client:Best-effort log streaming from SPCS will be enabled when python logging level is set to INFO.Alternatively, you can also query the logs by running the query 'CALL SYSTEM$GET_JOB_LOGS('01b0d0b2-0001-edf3-0046-30870003e8f6', 'kaniko')'\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Starting Kaniko command...\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Monitoring session token changes in the background...\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:29Z] Resolved base name mambaorg/micromamba:1.4.3 to build \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:29Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:29Z] Retrieving image mambaorg/micromamba:1.4.3 from registry index.docker.io \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Built cross stage deps: map[]                \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Executing 0 build triggers                   \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Building stage 'mambaorg/micromamba:1.4.3' [idx: '0', base-idx: '-1'] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Checking for cached layer sfsenorthamerica-build-spcs4.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/cache:e1ae53d782116824b29a4666146962e0d1c4b3fd51d50de0ce95e6c660156447... \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] No cached layer found for cmd RUN --mount=type=cache,target=/opt/conda/pkgs CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Cmd: USER                                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Cmd: USER                                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Cmd: EXPOSE                                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Adding exposed port: 5000/tcp                \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:30Z] Unpacking rootfs as cmd COPY env/conda.yml conda.yml requires it. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:33Z] Initializing snapshotter ...                 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:33Z] Taking snapshot of full filesystem...        \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] COPY env/conda.yml conda.yml                 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] COPY env/requirements.txt requirements.txt   \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] ARG MAMBA_DOCKERFILE_ACTIVATE=1              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] ENV CONDA_PREFIX=/opt/conda                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] RUN --mount=type=cache,target=/opt/conda/pkgs CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Cmd: /usr/local/bin/_dockerfile_shell.sh     \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Args: [CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:mambauser Name: HomeDir:/home/mambauser} \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Performing slow lookup of group ids for mambauser \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:38:34Z] Running: [/usr/local/bin/_dockerfile_shell.sh CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:                                           __\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      /_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Prefix: /opt/conda\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Updating specs:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - python=3.9\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - absl-py==1.4.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - anyio==3.5.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - cloudpickle==2.0.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - numpy==1.26.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - packaging==23.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pandas==1.5.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pyyaml==6.0.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - snowflake-snowpark-python==1.9.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - typing-extensions==4.7.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - sentencepiece\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - protobuf\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - transformers==4.34.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - scipy==1.11.4\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - conda-forge::accelerate[version='>=0.22.0']\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - nvidia::cuda=11.7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pytorch::pytorch==2.0.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pytorch::pytorch-cuda=11.7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Package                                          Version  Build                        Channel             Size\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Install:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _libgcc_mutex                                      0.1  conda_forge                  conda-forge          3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _openmp_mutex                                      4.5  2_gnu                        conda-forge         24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _sysroot_linux-64_curr_repodata_hack                 3  haa98f57_10                  pkgs/snowflake      13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + abseil-cpp                                  20211102.0  hd4dd3e8_0                   pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + absl-py                                          1.4.0  py39h06a4308_0               pkgs/snowflake     175kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + accelerate                                      0.25.0  pyhd8ed1ab_0                 conda-forge        179kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aiohttp                                          3.8.5  py39h5eee18b_0               pkgs/snowflake     462kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aiosignal                                        1.2.0  pyhd3eb1b0_0                 pkgs/snowflake      13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + anyio                                            3.5.0  py39h06a4308_0               pkgs/snowflake     162kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + arrow-cpp                                       10.0.1  h566e8be_2                   pkgs/snowflake      11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + asn1crypto                                       1.5.1  py39h06a4308_0               pkgs/snowflake     166kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + async-timeout                                    4.0.2  py39h06a4308_0               pkgs/snowflake      12kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + attrs                                           23.1.0  py39h06a4308_0               pkgs/snowflake     132kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-common                                     0.6.8  h5eee18b_1                   pkgs/snowflake     173kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-event-stream                               0.1.6  h6a678d5_6                   pkgs/snowflake      26kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-checksums                                   0.1.11  h5eee18b_2                   pkgs/snowflake      52kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-sdk-cpp                                    1.8.185  h721c034_1                   pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + binutils                                          2.40  hdd6e379_0                   conda-forge         30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + binutils_impl_linux-64                            2.40  hf600244_0                   conda-forge          5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + binutils_linux-64                                 2.40  hbdbef99_2                   conda-forge         28kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + blas                                               1.0  mkl                          pkgs/snowflake       6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + boost-cpp                                       1.82.0  hdb19cb5_2                   pkgs/snowflake      11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + bottleneck                                       1.3.5  py39h7deecbd_0               pkgs/snowflake     129kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + brotli-python                                    1.0.9  py39h6a678d5_7               pkgs/snowflake     362kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + bzip2                                            1.0.8  h7b6447c_0                   pkgs/snowflake     107kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + c-ares                                          1.19.1  h5eee18b_0                   pkgs/snowflake     116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + c-compiler                                       1.7.0  hd590300_0                   conda-forge          6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ca-certificates                             2023.08.22  h06a4308_0                   pkgs/snowflake     133kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + certifi                                      2023.7.22  py39h06a4308_0               pkgs/snowflake     159kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cffi                                            1.15.1  py39h5eee18b_3               pkgs/snowflake     235kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + charset-normalizer                               2.0.4  pyhd3eb1b0_0                 pkgs/snowflake      34kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + click                                            8.1.7  py39h06a4308_0               pkgs/snowflake     152kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cloudpickle                                      2.0.0  pyhd3eb1b0_0                 pkgs/snowflake      32kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cryptography                                    41.0.3  py39hdda0065_0               pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda                                            11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cccl                                     12.3.101  0                            nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-command-line-tools                         11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-compiler                                   12.0.0  h6459364_1                   conda-forge         20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cudart                                    11.7.99  0                            nvidia             199kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cudart-dev                                11.7.99  0                            nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cuobjdump                                 12.0.76  0                            nvidia             238kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cupti                                    11.7.101  0                            nvidia              24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cuxxfilt                                  12.0.76  0                            nvidia             299kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-demo-suite                               12.3.101  0                            nvidia               5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-documentation                            12.3.101  0                            nvidia              91kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-driver-dev                               12.3.101  0                            nvidia              18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-gdb                                      12.3.101  0                            nvidia               6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-libraries                                  11.7.1  0                            nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-libraries-dev                              11.7.1  0                            nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-memcheck                                  11.8.86  0                            nvidia             172kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nsight                                   12.3.101  0                            nvidia             119MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nsight-compute                             12.3.1  0                            nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvcc                                      12.0.76  0                            nvidia              54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvdisasm                                 12.3.101  0                            nvidia              50MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvml-dev                                 12.3.101  0                            nvidia              94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvprof                                   12.3.101  0                            nvidia               5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvprune                                   12.0.76  0                            nvidia              67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvrtc                                     11.7.99  0                            nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvrtc-dev                                 11.7.99  0                            nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvtx                                      11.7.91  0                            nvidia              58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvvp                                     12.3.101  0                            nvidia             120MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-runtime                                    11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-sanitizer-api                            12.3.101  0                            nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-toolkit                                    11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-tools                                      11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-visual-tools                               11.7.1  0                            nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cxx-compiler                                     1.7.0  h00ab1b0_0                   conda-forge          6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + dataclasses                                        0.8  pyh6d0b6a4_7                 pkgs/snowflake       7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + datasets                                        2.12.0  py39h06a4308_0               pkgs/snowflake     712kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + dill                                             0.3.6  py39h06a4308_0               pkgs/snowflake     160kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + filelock                                         3.9.0  py39h06a4308_0               pkgs/snowflake      18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + frozenlist                                       1.4.0  py39h5eee18b_0               pkgs/snowflake      58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + fsspec                                        2023.9.2  py39h06a4308_0               pkgs/snowflake     261kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gcc                                             12.3.0  h8d2909c_2                   conda-forge         27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gcc_impl_linux-64                               12.3.0  he2b93b0_3                   conda-forge         52MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gcc_linux-64                                    12.3.0  h76fc315_2                   conda-forge         30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gds-tools                                      1.8.1.2  0                            nvidia              43MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gflags                                           2.2.2  he6710b0_0                   pkgs/snowflake     164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + glog                                             0.5.0  h2531618_0                   pkgs/snowflake     108kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gmp                                              6.2.1  h295c915_3                   pkgs/snowflake     822kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gmpy2                                            2.1.2  py39heeb90bb_0               pkgs/snowflake     218kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + grpc-cpp                                        1.48.2  he1ff14a_1                   pkgs/snowflake       5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gxx                                             12.3.0  h8d2909c_2                   conda-forge         27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gxx_impl_linux-64                               12.3.0  he2b93b0_3                   conda-forge         13MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gxx_linux-64                                    12.3.0  h8a814eb_2                   conda-forge         29kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + huggingface_hub                                 0.17.3  py39h06a4308_0               pkgs/snowflake     416kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + icu                                               73.1  h6a678d5_0                   pkgs/snowflake      29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + idna                                               3.4  py39h06a4308_0               pkgs/snowflake     111kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + importlib-metadata                               6.0.0  py39h06a4308_0               pkgs/snowflake      38kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + importlib_metadata                               6.0.0  hd3eb1b0_0                   pkgs/snowflake       7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + intel-openmp                                  2023.1.0  hdb19cb5_46306               pkgs/snowflake      19MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + jinja2                                           3.1.2  py39h06a4308_0               pkgs/snowflake     212kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + joblib                                           1.2.0  py39h06a4308_0               pkgs/snowflake     403kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + kernel-headers_linux-64                         3.10.0  h57e8cba_10                  pkgs/snowflake     975kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + krb5                                            1.20.1  h143b758_1                   pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ld_impl_linux-64                                  2.40  h41732ed_0                   conda-forge        705kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libblas                                          3.9.0  1_h86c2bf4_netlib            conda-forge        203kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libboost                                        1.82.0  h109eef0_2                   pkgs/snowflake      24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlicommon                                  1.0.9  h5eee18b_7                   pkgs/snowflake      67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlidec                                     1.0.9  h5eee18b_7                   pkgs/snowflake      35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlienc                                     1.0.9  h5eee18b_7                   pkgs/snowflake     295kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcblas                                         3.9.0  5_h92ddd45_netlib            conda-forge         56kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcublas                                   11.10.3.66  0                            nvidia             300MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcublas-dev                               11.10.3.66  0                            nvidia             311MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufft                                    10.7.2.124  h4fbf590_0                   nvidia              98MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufft-dev                                10.7.2.124  h98a8f43_0                   nvidia             207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufile                                      1.8.1.2  0                            nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufile-dev                                  1.8.1.2  0                            nvidia              15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurand                                   10.3.4.101  0                            nvidia              54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurand-dev                               10.3.4.101  0                            nvidia             460kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurl                                          8.4.0  h251f7ec_0                   pkgs/snowflake     397kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusolver                                   11.4.0.1  0                            nvidia              83MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusolver-dev                               11.4.0.1  0                            nvidia              59MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusparse                                  11.7.4.91  0                            nvidia             158MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusparse-dev                              11.7.4.91  0                            nvidia             325MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libedit                                   3.1.20221030  h5eee18b_0                   pkgs/snowflake     196kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libev                                             4.33  h7f8727e_1                   pkgs/snowflake     109kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libevent                                        2.1.12  hdbd6064_1                   pkgs/snowflake     480kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libffi                                           3.4.4  h6a678d5_0                   pkgs/snowflake     148kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgcc-devel_linux-64                           12.3.0  h8bca6fd_103                 conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgcc-ng                                       13.2.0  h807b86a_3                   conda-forge        774kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgfortran-ng                                  13.2.0  h69a702a_3                   conda-forge         24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgfortran5                                    13.2.0  ha4646dd_3                   conda-forge          1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgomp                                         13.2.0  h807b86a_3                   conda-forge        422kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + liblapack                                        3.9.0  5_h92ddd45_netlib            conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnghttp2                                      1.57.0  h2d74bed_0                   pkgs/snowflake     722kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnpp                                       11.7.4.75  0                            nvidia             136MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnpp-dev                                   11.7.4.75  0                            nvidia             133MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnvjpeg                                     11.8.0.2  0                            nvidia               2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnvjpeg-dev                                 11.8.0.2  0                            nvidia               2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libprotobuf                                     3.20.3  he621ea3_0                   pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libsanitizer                                    12.3.0  h0f45ef3_3                   conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libssh2                                         1.10.0  hdbd6064_2                   pkgs/snowflake     311kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libstdcxx-devel_linux-64                        12.3.0  h8bca6fd_103                 conda-forge         12MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libstdcxx-ng                                    13.2.0  h7e041cc_3                   conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libthrift                                       0.15.0  h1795dd8_2                   pkgs/snowflake       5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + lz4-c                                            1.9.4  h6a678d5_0                   pkgs/snowflake     164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + markupsafe                                       2.1.1  py39h7f8727e_0               pkgs/snowflake      23kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl                                           2023.1.0  h213fc3f_46344               pkgs/snowflake     207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl-service                                      2.4.0  py39h5eee18b_1               pkgs/snowflake      59kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl_fft                                          1.3.8  py39h5eee18b_0               pkgs/snowflake     227kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl_random                                       1.2.4  py39hdb19cb5_0               pkgs/snowflake     329kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpc                                              1.1.0  h10f8cd9_1                   pkgs/snowflake      96kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpfr                                             4.0.2  hb69a4c5_1                   pkgs/snowflake     669kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpmath                                           1.3.0  py39h06a4308_0               pkgs/snowflake     991kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + multidict                                        6.0.2  py39h5eee18b_0               pkgs/snowflake      52kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + multiprocess                                   0.70.14  py39h06a4308_0               pkgs/snowflake     220kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ncurses                                            6.4  h6a678d5_0                   pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + networkx                                           3.1  py39h06a4308_0               pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + nsight-compute                              2023.3.1.1  0                            nvidia             847MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numexpr                                          2.8.7  py39h85018f9_0               pkgs/snowflake     141kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numpy                                           1.26.0  py39h5f9d8c6_0               pkgs/snowflake      10kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numpy-base                                      1.26.0  py39hb5e798b_0               pkgs/snowflake       8MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + openssl                                          3.2.0  hd590300_1                   conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + orc                                              1.7.4  hb3bc3d3_1                   pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + oscrypto                                         1.2.1  pyhd3eb1b0_0                 pkgs/snowflake     124kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + packaging                                         23.1  py39h06a4308_0               pkgs/snowflake      73kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pandas                                           1.5.3  py39h417a72b_0               pkgs/snowflake      14MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pip                                               23.3  py39h06a4308_0               pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + platformdirs                                     3.8.1  py39h06a4308_0               pkgs/snowflake      31kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + protobuf                                        3.20.3  py39h6a678d5_0               pkgs/snowflake     346kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + psutil                                           5.9.0  py39h5eee18b_0               pkgs/snowflake     353kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyarrow                                         10.0.1  py39h992f0b0_0               pkgs/snowflake       6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pycparser                                         2.21  pyhd3eb1b0_0                 pkgs/snowflake      97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pycryptodomex                                   3.15.0  py39h5eee18b_0               pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyjwt                                            2.4.0  py39h06a4308_0               pkgs/snowflake      35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyopenssl                                       23.2.0  py39h06a4308_0               pkgs/snowflake      94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pysocks                                          1.7.1  py39h06a4308_0               pkgs/snowflake      31kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python                                          3.9.18  h955ad1f_0                   pkgs/snowflake      27MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python-dateutil                       2.8.3+snowflake1  py39h06a4308_1               pkgs/snowflake     324kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python-xxhash                                    2.0.2  py39h5eee18b_1               pkgs/snowflake      22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python_abi                                         3.9  2_cp39                       conda-forge          4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch                                          2.0.1  py3.9_cuda11.7_cudnn8.5.0_0  pytorch              1GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch-cuda                                      11.7  h778d358_5                   pytorch              4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch-mutex                                      1.0  cuda                         pytorch              3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytz                                      2023.3.post1  py39h06a4308_0               pkgs/snowflake     258kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyyaml                                           6.0.1  py39h5eee18b_0               pkgs/snowflake     184kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + re2                                         2022.04.01  h295c915_0                   pkgs/snowflake     235kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + readline                                           8.2  h5eee18b_0                   pkgs/snowflake     468kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + regex                                        2023.10.3  py39h5eee18b_0               pkgs/snowflake     393kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + requests                                        2.31.0  py39h06a4308_0               pkgs/snowflake      94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + responses                                       0.13.3  pyhd3eb1b0_0                 pkgs/snowflake      25kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sacremoses                                      0.0.43  pyhd3eb1b0_0                 pkgs/snowflake     452kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + safetensors                                      0.4.0  py39ha89cbab_0               pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + scipy                                           1.11.4  py39h474f0d3_0               conda-forge         15MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sentencepiece                                   0.1.99  py39hdb19cb5_0               pkgs/snowflake       9MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + setuptools                                      68.0.0  py39h06a4308_0               pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + six                                             1.16.0  pyhd3eb1b0_1                 pkgs/snowflake      19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snappy                                           1.1.9  h295c915_0                   pkgs/snowflake     891kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sniffio                                          1.2.0  py39h06a4308_1               pkgs/snowflake      16kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snowflake-connector-python                       3.2.0  py39h1128e8f_1               pkgs/snowflake     812kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snowflake-snowpark-python                        1.9.0  py39h06a4308_0               pkgs/snowflake     518kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sortedcontainers                                 2.4.0  pyhd3eb1b0_0                 pkgs/snowflake      27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sqlite                                          3.41.2  h5eee18b_0                   pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sympy                                           1.11.1  py39h06a4308_0               pkgs/snowflake      12MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sysroot_linux-64                                  2.17  h57e8cba_10                  pkgs/snowflake      34MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tbb                                           2021.8.0  hdb19cb5_0                   pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tk                                              8.6.12  h1ccaba5_0                   pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tokenizers                                      0.14.1  py39hc62d755_2               conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tomlkit                                         0.11.1  py39h06a4308_0               pkgs/snowflake      71kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + torchtriton                                      2.0.0  py39                         pytorch             66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tqdm                                            4.65.0  py39hb070fc8_0               pkgs/snowflake     124kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + transformers                                    4.34.0  pyhd8ed1ab_0                 conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + typing-extensions                                4.7.1  py39h06a4308_0               pkgs/snowflake       9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + typing_extensions                                4.7.1  py39h06a4308_0               pkgs/snowflake      57kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tzdata                                           2023c  h04d1e81_0                   pkgs/snowflake     122kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + urllib3                                        1.26.18  py39h06a4308_0               pkgs/snowflake     187kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + utf8proc                                         2.6.1  h27cfd23_0                   pkgs/snowflake     309kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + wheel                                           0.41.2  py39h06a4308_0               pkgs/snowflake     102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + xxhash                                           0.8.0  h7f8727e_3                   pkgs/snowflake      93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + xz                                               5.4.5  h5eee18b_0                   pkgs/snowflake     708kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + yaml                                             0.2.5  h7b6447c_0                   pkgs/snowflake      89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + yarl                                             1.8.1  py39h5eee18b_0               pkgs/snowflake      91kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zipp                                            3.11.0  py39h06a4308_0               pkgs/snowflake      18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zlib                                            1.2.13  h5eee18b_0                   pkgs/snowflake     128kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zstd                                             1.5.5  hc292b87_0                   pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Summary:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Install: 216 packages\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Total download: 5GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction starting\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvrtc-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cudart-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcublas-11.10.3.66-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusolver-11.4.0.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusparse-11.7.4.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnpp-11.7.4.75-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnvjpeg-11.8.0.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvtx-11.7.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cupti-11.7.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cupti-11.7.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nsight-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nsight-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvml-dev-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvml-dev-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking nsight-compute-2023.3.1.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [nsight-compute-2023.3.1.1-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufile-1.8.1.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cuobjdump-12.0.76-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cuobjdump-12.0.76-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cuxxfilt-12.0.76-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cuxxfilt-12.0.76-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvcc-12.0.76-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvcc-12.0.76-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvprune-12.0.76-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvprune-12.0.76-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-documentation-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-documentation-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvdisasm-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvdisasm-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvprof-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvprof-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cccl-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-driver-dev-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufft-10.7.2.124-h4fbf590_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurand-10.3.4.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-gdb-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-sanitizer-api-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-sanitizer-api-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-memcheck-11.8.86-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-memcheck-11.8.86-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-demo-suite-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-demo-suite-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvrtc-dev-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcublas-dev-11.10.3.66-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusolver-dev-11.4.0.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusparse-dev-11.7.4.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [libcusparse-dev-11.7.4.91-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - lib/libcusparse.so.11\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - lib/libcusparse.so.11.7.4.91\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnpp-dev-11.7.4.75-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnvjpeg-dev-11.8.0.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nsight-compute-12.3.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufile-dev-1.8.1.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gds-tools-1.8.1.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvvp-12.3.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvvp-12.3.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cudart-dev-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufft-dev-10.7.2.124-h98a8f43_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurand-dev-10.3.4.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-libraries-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-command-line-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-libraries-dev-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-runtime-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-visual-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _libgcc_mutex-0.1-conda_forge\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libstdcxx-ng-13.2.0-h7e041cc_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ld_impl_linux-64-2.40-h41732ed_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgomp-13.2.0-h807b86a_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _openmp_mutex-4.5-2_gnu\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgcc-ng-13.2.0-h807b86a_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libsanitizer-12.3.0-h0f45ef3_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgfortran5-13.2.0-ha4646dd_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgfortran-ng-13.2.0-h69a702a_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libblas-3.9.0-1_h86c2bf4_netlib\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking liblapack-3.9.0-5_h92ddd45_netlib\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcblas-3.9.0-5_h92ddd45_netlib\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ca-certificates-2023.08.22-h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking blas-1.0-mkl\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libev-4.33-h7f8727e_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking c-ares-1.19.1-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking xxhash-0.8.0-h7f8727e_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snappy-1.1.9-h295c915_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking re2-2022.04.01-h295c915_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking lz4-c-1.9.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlicommon-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking abseil-cpp-20211102.0-hd4dd3e8_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-common-0.6.8-h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking icu-73.1-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking bzip2-1.0.8-h7b6447c_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tbb-2021.8.0-hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gflags-2.2.2-he6710b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gmp-6.2.1-h295c915_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zlib-1.2.13-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking xz-5.4.5-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ncurses-6.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libffi-3.4.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking yaml-0.2.5-h7b6447c_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking utf8proc-2.6.1-h27cfd23_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlidec-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlienc-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-checksums-0.1.11-h5eee18b_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking glog-0.5.0-h2531618_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpfr-4.0.2-hb69a4c5_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libprotobuf-3.20.3-he621ea3_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tk-8.6.12-h1ccaba5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zstd-1.5.5-hc292b87_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libedit-3.1.20221030-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking readline-8.2-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking intel-openmp-2023.1.0-hdb19cb5_46306\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-event-stream-0.1.6-h6a678d5_6\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpc-1.1.0-h10f8cd9_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking orc-1.7.4-hb3bc3d3_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libboost-1.82.0-h109eef0_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sqlite-3.41.2-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl-2023.1.0-h213fc3f_46344\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking boost-cpp-1.82.0-hdb19cb5_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _sysroot_linux-64_curr_repodata_hack-3-haa98f57_10\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tzdata-2023c-h04d1e81_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking kernel-headers_linux-64-3.10.0-h57e8cba_10\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sysroot_linux-64-2.17-h57e8cba_10\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libstdcxx-devel_linux-64-12.3.0-h8bca6fd_103\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgcc-devel_linux-64-12.3.0-h8bca6fd_103\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytorch-cuda-11.7-h778d358_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking openssl-3.2.0-hd590300_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking binutils_impl_linux-64-2.40-hf600244_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gcc_impl_linux-64-12.3.0-he2b93b0_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking binutils-2.40-hdd6e379_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking binutils_linux-64-2.40-hbdbef99_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gcc-12.3.0-h8d2909c_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gxx_impl_linux-64-12.3.0-he2b93b0_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gcc_linux-64-12.3.0-h76fc315_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gxx-12.3.0-h8d2909c_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gxx_linux-64-12.3.0-h8a814eb_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking c-compiler-1.7.0-hd590300_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cxx-compiler-1.7.0-h00ab1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libssh2-1.10.0-hdbd6064_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking krb5-1.20.1-h143b758_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libevent-2.1.12-hdbd6064_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking grpc-cpp-1.48.2-he1ff14a_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnghttp2-1.57.0-h2d74bed_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-3.9.18-h955ad1f_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking wheel-0.41.2-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libthrift-0.15.0-h1795dd8_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurl-8.4.0-h251f7ec_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking setuptools-68.0.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-sdk-cpp-1.8.185-h721c034_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pip-23.3-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking arrow-cpp-10.0.1-h566e8be_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pysocks-1.7.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking brotli-python-1.0.9-py39h6a678d5_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking multidict-6.0.2-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking frozenlist-1.4.0-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking attrs-23.1.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking async-timeout-4.0.2-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sniffio-1.2.0-py39h06a4308_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-xxhash-2.0.2-py39h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking dill-0.3.6-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking fsspec-2023.9.2-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zipp-3.11.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking markupsafe-2.1.1-py39h7f8727e_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tomlkit-0.11.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytz-2023.3.post1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyjwt-2.4.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pycryptodomex-3.15.0-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking platformdirs-3.8.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking idna-3.4-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking certifi-2023.7.22-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking asn1crypto-1.5.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpmath-1.3.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gmpy2-2.1.2-py39heeb90bb_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking joblib-1.2.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking click-8.1.7-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking networkx-3.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl-service-2.4.0-py39h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking psutil-5.9.0-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tqdm-4.65.0-py39hb070fc8_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking safetensors-0.4.0-py39ha89cbab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking regex-2023.10.3-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking filelock-3.9.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking protobuf-3.20.3-py39h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sentencepiece-0.1.99-py39hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking typing_extensions-4.7.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyyaml-6.0.1-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking packaging-23.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking absl-py-1.4.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking multiprocess-0.70.14-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking importlib-metadata-6.0.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking jinja2-3.1.2-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking yarl-1.8.1-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking anyio-3.5.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sympy-1.11.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numpy-base-1.26.0-py39hb5e798b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking typing-extensions-4.7.1-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numpy-1.26.0-py39h5f9d8c6_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl_fft-1.3.8-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl_random-1.2.4-py39hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numexpr-2.8.7-py39h85018f9_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking bottleneck-1.3.5-py39h7deecbd_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyarrow-10.0.1-py39h992f0b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-compiler-12.0.0-h6459364_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pycparser-2.21-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sortedcontainers-2.4.0-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking six-1.16.0-pyhd3eb1b0_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking dataclasses-0.8-pyh6d0b6a4_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cloudpickle-2.0.0-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aiosignal-1.2.0-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking oscrypto-1.2.1-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking importlib_metadata-6.0.0-hd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sacremoses-0.0.43-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python_abi-3.9-2_cp39\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking scipy-1.11.4-py39h474f0d3_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytorch-2.0.1-py3.9_cuda11.7_cudnn8.5.0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking torchtriton-2.0.0-py39\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-toolkit-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cffi-1.15.1-py39h5eee18b_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-dateutil-2.8.3+snowflake1-py39h06a4308_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aiohttp-3.8.5-py39h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cryptography-41.0.3-py39hdda0065_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pandas-1.5.3-py39h417a72b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyopenssl-23.2.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking urllib3-1.26.18-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking requests-2.31.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snowflake-connector-python-3.2.0-py39h1128e8f_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking huggingface_hub-0.17.3-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snowflake-snowpark-python-1.9.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking accelerate-0.25.0-pyhd8ed1ab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking responses-0.13.3-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tokenizers-0.14.1-py39hc62d755_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking datasets-2.12.0-py39h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking transformers-4.34.0-pyhd8ed1ab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction finished\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:To activate this environment, use:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    micromamba activate base\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Or to execute a single command in this environment, use:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    micromamba run -n base mycommand\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting gunicorn\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting starlette==0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading starlette-0.30.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting uvicorn[standard]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading uvicorn-0.24.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from starlette==0.30.0) (3.5.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/lib/python3.9/site-packages (from starlette==0.30.0) (4.7.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]) (8.1.7)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting h11>=0.8 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 3.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting httptools>=0.5.0 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]) (6.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from gunicorn) (23.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.30.0) (3.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.30.0) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading starlette-0.30.0-py3-none-any.whl (68 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.8/68.8 kB 8.4 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.2/80.2 kB 7.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.2/345.2 kB 16.6 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 71.9 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 50.6 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.0/130.0 kB 9.6 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.7/59.7 kB 7.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Installing collected packages: websockets, uvloop, python-dotenv, httptools, h11, gunicorn, watchfiles, uvicorn, starlette\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting peft==0.5.0 (from -r requirements.txt (line 1))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting vllm==0.2.1.post1 (from -r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading vllm-0.2.1.post1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.2 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting bitsandbytes>=0.41.0 (from -r requirements.txt (line 3))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl.metadata (9.8 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (1.26.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (23.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (5.9.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (4.34.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (4.65.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: accelerate in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (0.25.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: safetensors in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting ninja (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting ray>=2.5.1 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading ray-2.8.1-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.5.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (10.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.1.99)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting xformers==0.0.22 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading xformers-0.0.22-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting fastapi (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.9/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.24.0.post1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting pydantic<2 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 4.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.9.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (4.7.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (1.11.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (8.1.7)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting jsonschema (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading jsonschema-4.20.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading msgpack-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.9/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (3.20.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: aiosignal in /opt/conda/lib/python3.9/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: frozenlist in /opt/conda/lib/python3.9/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.4.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.31.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.9/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (0.17.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (2023.10.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.9/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (0.14.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting anyio<4.0.0,>=3.7.1 (from fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting starlette<0.28.0,>=0.27.0 (from fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting typing-extensions (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.8.3+snowflake1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.14.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.6.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.0.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.19.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.21.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.9/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (12.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2)) (3.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting exceptiongroup (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->peft==0.5.0->-r requirements.txt (line 1)) (2023.9.2)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.16.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (2.1.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (23.1.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading jsonschema_specifications-2023.11.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting referencing>=0.28.4 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading referencing-0.31.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting rpds-py>=0.7.1 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading rpds_py-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.0.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.26.18)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2023.7.22)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 13.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading vllm-0.2.1.post1-cp39-cp39-manylinux1_x86_64.whl (28.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.6/28.6 MB 59.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading xformers-0.0.22-cp39-cp39-manylinux2014_x86_64.whl (211.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.6/211.6 MB 13.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 29.4 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 100.4 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading ray-2.8.1-cp39-cp39-manylinux2014_x86_64.whl (62.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 MB 47.6 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.9/92.9 kB 14.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 21.0 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 kB 10.2 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading msgpack-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 531.0/531.0 kB 39.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 6.9 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 7.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading jsonschema_specifications-2023.11.2-py3-none-any.whl (17 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading referencing-0.31.1-py3-none-any.whl (25 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading rpds_py-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 68.3 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Installing collected packages: ninja, bitsandbytes, typing-extensions, rpds-py, msgpack, exceptiongroup, referencing, pydantic, anyio, xformers, starlette, jsonschema-specifications, jsonschema, fastapi, ray, peft, vllm\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Attempting uninstall: typing-extensions\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Found existing installation: typing_extensions 4.7.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Uninstalling typing_extensions-4.7.1:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      Successfully uninstalled typing_extensions-4.7.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Attempting uninstall: anyio\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Found existing installation: anyio 3.5.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Uninstalling anyio-3.5.0:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      Successfully uninstalled anyio-3.5.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Attempting uninstall: starlette\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Found existing installation: starlette 0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Uninstalling starlette-0.30.0:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      Successfully uninstalled starlette-0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:triton 2.0.0 requires cmake, which is not installed.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:triton 2.0.0 requires lit, which is not installed.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Successfully installed anyio-3.7.1 bitsandbytes-0.41.2.post2 exceptiongroup-1.2.0 fastapi-0.104.1 jsonschema-4.20.0 jsonschema-specifications-2023.11.2 msgpack-1.0.7 ninja-1.11.1.1 peft-0.5.0 pydantic-1.10.13 ray-2.8.1 referencing-0.31.1 rpds-py-0.13.2 starlette-0.27.0 typing-extensions-4.8.0 vllm-0.2.1.post1 xformers-0.0.22\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:                                           __\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      /_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collect information..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning index cache..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning lock files..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Package file                                                   Size\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  /opt/conda/pkgs\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _libgcc_mutex-0.1-conda_forge.tar.bz2                           3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _openmp_mutex-4.5-2_gnu.tar.bz2                                24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _sysroot_linux-64_curr_repodata_hack-3-haa98f57_10.tar.bz2     13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  abseil-cpp-20211102.0-hd4dd3e8_0.tar.bz2                        1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  absl-py-1.4.0-py39h06a4308_0.tar.bz2                          175kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  accelerate-0.25.0-pyhd8ed1ab_0.conda                          179kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aiohttp-3.8.5-py39h5eee18b_0.tar.bz2                          462kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aiosignal-1.2.0-pyhd3eb1b0_0.tar.bz2                           13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  anyio-3.5.0-py39h06a4308_0.tar.bz2                            162kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  arrow-cpp-10.0.1-h566e8be_2.tar.bz2                            11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  asn1crypto-1.5.1-py39h06a4308_0.tar.bz2                       166kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  async-timeout-4.0.2-py39h06a4308_0.tar.bz2                     12kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  attrs-23.1.0-py39h06a4308_0.tar.bz2                           132kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-common-0.6.8-h5eee18b_1.tar.bz2                         173kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-event-stream-0.1.6-h6a678d5_6.tar.bz2                    26kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-checksums-0.1.11-h5eee18b_2.tar.bz2                        52kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-sdk-cpp-1.8.185-h721c034_1.tar.bz2                          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  binutils-2.40-hdd6e379_0.conda                                 30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  binutils_impl_linux-64-2.40-hf600244_0.conda                    5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  binutils_linux-64-2.40-hbdbef99_2.conda                        28kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  blas-1.0-mkl.tar.bz2                                            6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  boost-cpp-1.82.0-hdb19cb5_2.tar.bz2                            11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  bottleneck-1.3.5-py39h7deecbd_0.tar.bz2                       129kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  brotli-python-1.0.9-py39h6a678d5_7.tar.bz2                    362kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  bzip2-1.0.8-h7b6447c_0.tar.bz2                                107kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  c-ares-1.19.1-h5eee18b_0.tar.bz2                              116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  c-compiler-1.7.0-hd590300_0.conda                               6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ca-certificates-2023.08.22-h06a4308_0.tar.bz2                 133kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  certifi-2023.7.22-py39h06a4308_0.tar.bz2                      159kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cffi-1.15.1-py39h5eee18b_3.tar.bz2                            235kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  charset-normalizer-2.0.4-pyhd3eb1b0_0.tar.bz2                  34kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  click-8.1.7-py39h06a4308_0.tar.bz2                            152kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cloudpickle-2.0.0-pyhd3eb1b0_0.tar.bz2                         32kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cryptography-41.0.3-py39hdda0065_0.tar.bz2                      2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-11.7.1-0.tar.bz2                                           1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cccl-12.3.101-0.tar.bz2                                    1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-command-line-tools-11.7.1-0.tar.bz2                        1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-compiler-12.0.0-h6459364_1.conda                          20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cudart-11.7.99-0.tar.bz2                                 199kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cudart-dev-11.7.99-0.tar.bz2                               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cuobjdump-12.0.76-0.tar.bz2                              238kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cupti-11.7.101-0.tar.bz2                                  24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cuxxfilt-12.0.76-0.tar.bz2                               299kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-demo-suite-12.3.101-0.tar.bz2                              5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-documentation-12.3.101-0.tar.bz2                          91kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-driver-dev-12.3.101-0.tar.bz2                             18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-gdb-12.3.101-0.tar.bz2                                     6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-libraries-11.7.1-0.tar.bz2                                 2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-libraries-dev-11.7.1-0.tar.bz2                             2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-memcheck-11.8.86-0.tar.bz2                               172kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nsight-12.3.101-0.tar.bz2                                119MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nsight-compute-12.3.1-0.tar.bz2                            2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvcc-12.0.76-0.tar.bz2                                    54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvdisasm-12.3.101-0.tar.bz2                               50MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvml-dev-12.3.101-0.tar.bz2                               94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvprof-12.3.101-0.tar.bz2                                  5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvprune-12.0.76-0.tar.bz2                                 67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvrtc-11.7.99-0.tar.bz2                                   18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvrtc-dev-11.7.99-0.tar.bz2                               18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvtx-11.7.91-0.tar.bz2                                    58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvvp-12.3.101-0.tar.bz2                                  120MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-runtime-11.7.1-0.tar.bz2                                   1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-sanitizer-api-12.3.101-0.tar.bz2                          18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-toolkit-11.7.1-0.tar.bz2                                   1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-tools-11.7.1-0.tar.bz2                                     1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-visual-tools-11.7.1-0.tar.bz2                              1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cxx-compiler-1.7.0-h00ab1b0_0.conda                             6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  dataclasses-0.8-pyh6d0b6a4_7.tar.bz2                            7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  datasets-2.12.0-py39h06a4308_0.tar.bz2                        712kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  dill-0.3.6-py39h06a4308_0.tar.bz2                             160kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  filelock-3.9.0-py39h06a4308_0.tar.bz2                          18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  frozenlist-1.4.0-py39h5eee18b_0.tar.bz2                        58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  fsspec-2023.9.2-py39h06a4308_0.tar.bz2                        261kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gcc-12.3.0-h8d2909c_2.conda                                    27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gcc_impl_linux-64-12.3.0-he2b93b0_3.conda                      52MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gcc_linux-64-12.3.0-h76fc315_2.conda                           30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gds-tools-1.8.1.2-0.tar.bz2                                    43MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gflags-2.2.2-he6710b0_0.tar.bz2                               164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  glog-0.5.0-h2531618_0.tar.bz2                                 108kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gmp-6.2.1-h295c915_3.tar.bz2                                  822kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gmpy2-2.1.2-py39heeb90bb_0.tar.bz2                            218kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  grpc-cpp-1.48.2-he1ff14a_1.tar.bz2                              5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gxx-12.3.0-h8d2909c_2.conda                                    27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gxx_impl_linux-64-12.3.0-he2b93b0_3.conda                      13MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gxx_linux-64-12.3.0-h8a814eb_2.conda                           29kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  huggingface_hub-0.17.3-py39h06a4308_0.tar.bz2                 416kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  icu-73.1-h6a678d5_0.tar.bz2                                    29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  idna-3.4-py39h06a4308_0.tar.bz2                               111kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  importlib-metadata-6.0.0-py39h06a4308_0.tar.bz2                38kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  importlib_metadata-6.0.0-hd3eb1b0_0.tar.bz2                     7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  intel-openmp-2023.1.0-hdb19cb5_46306.tar.bz2                   19MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  jinja2-3.1.2-py39h06a4308_0.tar.bz2                           212kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  joblib-1.2.0-py39h06a4308_0.tar.bz2                           403kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  kernel-headers_linux-64-3.10.0-h57e8cba_10.tar.bz2            975kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  krb5-1.20.1-h143b758_1.tar.bz2                                  1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ld_impl_linux-64-2.40-h41732ed_0.conda                        705kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libblas-3.9.0-1_h86c2bf4_netlib.tar.bz2                       203kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libboost-1.82.0-h109eef0_2.tar.bz2                             24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlicommon-1.0.9-h5eee18b_7.tar.bz2                       67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlidec-1.0.9-h5eee18b_7.tar.bz2                          35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlienc-1.0.9-h5eee18b_7.tar.bz2                         295kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcblas-3.9.0-5_h92ddd45_netlib.tar.bz2                       56kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcublas-11.10.3.66-0.tar.bz2                                300MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcublas-dev-11.10.3.66-0.tar.bz2                            311MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufft-10.7.2.124-h4fbf590_0.tar.bz2                         98MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufft-dev-10.7.2.124-h98a8f43_0.tar.bz2                    207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufile-1.8.1.2-0.tar.bz2                                     1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufile-dev-1.8.1.2-0.tar.bz2                                15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurand-10.3.4.101-0.tar.bz2                                 54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurand-dev-10.3.4.101-0.tar.bz2                            460kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurl-8.4.0-h251f7ec_0.tar.bz2                              397kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusolver-11.4.0.1-0.tar.bz2                                 83MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusolver-dev-11.4.0.1-0.tar.bz2                             59MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusparse-11.7.4.91-0.tar.bz2                               158MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusparse-dev-11.7.4.91-0.tar.bz2                           325MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libedit-3.1.20221030-h5eee18b_0.tar.bz2                       196kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libev-4.33-h7f8727e_1.tar.bz2                                 109kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libevent-2.1.12-hdbd6064_1.tar.bz2                            480kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libffi-3.4.4-h6a678d5_0.tar.bz2                               148kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgcc-devel_linux-64-12.3.0-h8bca6fd_103.conda                 3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgcc-ng-13.2.0-h807b86a_3.conda                             774kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgfortran-ng-13.2.0-h69a702a_3.conda                         24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgfortran5-13.2.0-ha4646dd_3.conda                            1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgomp-13.2.0-h807b86a_3.conda                               422kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  liblapack-3.9.0-5_h92ddd45_netlib.tar.bz2                       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnghttp2-1.57.0-h2d74bed_0.tar.bz2                          722kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnpp-11.7.4.75-0.tar.bz2                                    136MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnpp-dev-11.7.4.75-0.tar.bz2                                133MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnvjpeg-11.8.0.2-0.tar.bz2                                    2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnvjpeg-dev-11.8.0.2-0.tar.bz2                                2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libprotobuf-3.20.3-he621ea3_0.tar.bz2                           3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libsanitizer-12.3.0-h0f45ef3_3.conda                            4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libssh2-1.10.0-hdbd6064_2.tar.bz2                             311kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libstdcxx-devel_linux-64-12.3.0-h8bca6fd_103.conda             12MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libstdcxx-ng-13.2.0-h7e041cc_3.conda                            4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libthrift-0.15.0-h1795dd8_2.tar.bz2                             5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  lz4-c-1.9.4-h6a678d5_0.tar.bz2                                164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  markupsafe-2.1.1-py39h7f8727e_0.tar.bz2                        23kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl-2023.1.0-h213fc3f_46344.tar.bz2                           207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl-service-2.4.0-py39h5eee18b_1.tar.bz2                       59kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl_fft-1.3.8-py39h5eee18b_0.tar.bz2                          227kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl_random-1.2.4-py39hdb19cb5_0.tar.bz2                       329kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpc-1.1.0-h10f8cd9_1.tar.bz2                                   96kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpfr-4.0.2-hb69a4c5_1.tar.bz2                                 669kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpmath-1.3.0-py39h06a4308_0.tar.bz2                           991kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  multidict-6.0.2-py39h5eee18b_0.tar.bz2                         52kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  multiprocess-0.70.14-py39h06a4308_0.tar.bz2                   220kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ncurses-6.4-h6a678d5_0.tar.bz2                                  1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  networkx-3.1-py39h06a4308_0.tar.bz2                             3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  nsight-compute-2023.3.1.1-0.tar.bz2                           847MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numexpr-2.8.7-py39h85018f9_0.tar.bz2                          141kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numpy-1.26.0-py39h5f9d8c6_0.tar.bz2                            10kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numpy-base-1.26.0-py39hb5e798b_0.tar.bz2                        8MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  openssl-3.2.0-hd590300_1.conda                                  3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  orc-1.7.4-hb3bc3d3_1.tar.bz2                                    1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  oscrypto-1.2.1-pyhd3eb1b0_0.tar.bz2                           124kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  packaging-23.1-py39h06a4308_0.tar.bz2                          73kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pandas-1.5.3-py39h417a72b_0.tar.bz2                            14MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pip-23.3-py39h06a4308_0.tar.bz2                                 3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  platformdirs-3.8.1-py39h06a4308_0.tar.bz2                      31kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  protobuf-3.20.3-py39h6a678d5_0.tar.bz2                        346kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  psutil-5.9.0-py39h5eee18b_0.tar.bz2                           353kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyarrow-10.0.1-py39h992f0b0_0.tar.bz2                           6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pycparser-2.21-pyhd3eb1b0_0.tar.bz2                            97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pycryptodomex-3.15.0-py39h5eee18b_0.tar.bz2                     2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyjwt-2.4.0-py39h06a4308_0.tar.bz2                             35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyopenssl-23.2.0-py39h06a4308_0.tar.bz2                        94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pysocks-1.7.1-py39h06a4308_0.tar.bz2                           31kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-3.9.18-h955ad1f_0.tar.bz2                               27MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-dateutil-2.8.3+snowflake1-py39h06a4308_1.tar.bz2       324kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-xxhash-2.0.2-py39h5eee18b_1.tar.bz2                     22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python_abi-3.9-2_cp39.tar.bz2                                   4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-2.0.1-py3.9_cuda11.7_cudnn8.5.0_0.tar.bz2               1GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-cuda-11.7-h778d358_5.tar.bz2                            4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-mutex-1.0-cuda.tar.bz2                                  3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytz-2023.3.post1-py39h06a4308_0.tar.bz2                      258kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyyaml-6.0.1-py39h5eee18b_0.tar.bz2                           184kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  re2-2022.04.01-h295c915_0.tar.bz2                             235kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  readline-8.2-h5eee18b_0.tar.bz2                               468kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  regex-2023.10.3-py39h5eee18b_0.tar.bz2                        393kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  requests-2.31.0-py39h06a4308_0.tar.bz2                         94kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  responses-0.13.3-pyhd3eb1b0_0.tar.bz2                          25kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sacremoses-0.0.43-pyhd3eb1b0_0.tar.bz2                        452kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  safetensors-0.4.0-py39ha89cbab_0.tar.bz2                        1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  scipy-1.11.4-py39h474f0d3_0.conda                              15MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sentencepiece-0.1.99-py39hdb19cb5_0.tar.bz2                     9MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  setuptools-68.0.0-py39h06a4308_0.tar.bz2                        1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  six-1.16.0-pyhd3eb1b0_1.tar.bz2                                19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snappy-1.1.9-h295c915_0.tar.bz2                               891kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sniffio-1.2.0-py39h06a4308_1.tar.bz2                           16kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snowflake-connector-python-3.2.0-py39h1128e8f_1.tar.bz2       812kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snowflake-snowpark-python-1.9.0-py39h06a4308_0.tar.bz2        518kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sortedcontainers-2.4.0-pyhd3eb1b0_0.tar.bz2                    27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sqlite-3.41.2-h5eee18b_0.tar.bz2                                2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sympy-1.11.1-py39h06a4308_0.tar.bz2                            12MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sysroot_linux-64-2.17-h57e8cba_10.tar.bz2                      34MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tbb-2021.8.0-hdb19cb5_0.tar.bz2                                 2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tk-8.6.12-h1ccaba5_0.tar.bz2                                    3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tokenizers-0.14.1-py39hc62d755_2.conda                          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tomlkit-0.11.1-py39h06a4308_0.tar.bz2                          71kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  torchtriton-2.0.0-py39.tar.bz2                                 66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tqdm-4.65.0-py39hb070fc8_0.tar.bz2                            124kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  transformers-4.34.0-pyhd8ed1ab_0.conda                          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  typing-extensions-4.7.1-py39h06a4308_0.tar.bz2                  9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  typing_extensions-4.7.1-py39h06a4308_0.tar.bz2                 57kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tzdata-2023c-h04d1e81_0.tar.bz2                               122kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  urllib3-1.26.18-py39h06a4308_0.tar.bz2                        187kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  utf8proc-2.6.1-h27cfd23_0.tar.bz2                             309kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  wheel-0.41.2-py39h06a4308_0.tar.bz2                           102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  xxhash-0.8.0-h7f8727e_3.tar.bz2                                93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  xz-5.4.5-h5eee18b_0.tar.bz2                                   708kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  yaml-0.2.5-h7b6447c_0.tar.bz2                                  89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  yarl-1.8.1-py39h5eee18b_0.tar.bz2                              91kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zipp-3.11.0-py39h06a4308_0.tar.bz2                             18kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zlib-1.2.13-h5eee18b_0.tar.bz2                                128kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zstd-1.5.5-hc292b87_0.tar.bz2                                   1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  /home/mambauser/.mamba/pkgs\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:───────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Total size:                                                     5GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning tarballs..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning packages..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:43:27Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:29Z] Running: [/usr/local/bin/_dockerfile_shell.sh if id mambauser >/dev/null 2>&1; then         echo \"mambauser already exists.\";     else         export USER=mambauser &&         export UID=1000 &&         export HOME=/home/$USER &&         echo \"Creating $USER user...\" &&         adduser --disabled-password             --gecos \"A non-root user for running inference server\"             --uid $UID             --home $HOME             $USER;     fi] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:mambauser already exists.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:31Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:31Z] RUN chmod +x ./gunicorn_run.sh               \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:33Z] Cmd: /usr/local/bin/_dockerfile_shell.sh     \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:33Z] Args: [chmod +x ./gunicorn_run.sh]           \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:33Z] Util.Lookup returned: &{Uid:0 Gid:0 Username:root Name: HomeDir:/root} \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:33Z] Performing slow lookup of group ids for root \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:33Z] Running: [/usr/local/bin/_dockerfile_shell.sh chmod +x ./gunicorn_run.sh] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] USER mambauser                               \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Cmd: USER                                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Pushing layer sfsenorthamerica-build-spcs4.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/cache:ee320471e77cf4e909879efdbb49128e12c583806340d64d2df3bb38ed64b7cb to cache now \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Pushing image to sfsenorthamerica-build-spcs4.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/cache:ee320471e77cf4e909879efdbb49128e12c583806340d64d2df3bb38ed64b7cb \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] EXPOSE 5000                                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Cmd: EXPOSE                                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] Adding exposed port: 5000/tcp                \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] CMD [\"./gunicorn_run.sh\"]                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2023-12-06T21:46:36Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Time taken to build and upload image to registry: 1031.84 seconds\n",
      "WARNING:snowflake.ml.model._deploy_client.snowservice.deploy:Image successfully built! For future model deployments, the image will be reused if possible, saving model deployment time. To enforce using the same image, include 'prebuilt_snowflake_image': 'sfsenorthamerica-build-spcs4.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/9489d6af5ab9b9440cf603eb7844a8c09e9d1603:latest' in the deploy() function's options.\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))': /login\n",
      "INFO:snowflake.ml.model._deploy_client.utils.snowservice_client:Creating service DB_USER0007.SCHEMA_LLM.service_6f58d2de947f11eeb19facde48001122\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Wait for service DB_USER0007.SCHEMA_LLM.service_6f58d2de947f11eeb19facde48001122 to become ready...\n",
      "WARNING:snowflake.ml.model._deploy_client.utils.snowservice_client:Best-effort log streaming from SPCS will be enabled when python logging level is set to INFO.Alternatively, you can also query the logs by running the query 'CALL SYSTEM$GET_SERVICE_LOGS('DB_USER0007.SCHEMA_LLM.service_6f58d2de947f11eeb19facde48001122', '0', 'inference-server')'\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Number of CPU cores: 8\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Setting number of workers to 1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:41 +0000] [1] [INFO] Starting gunicorn 21.2.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:41 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:41 +0000] [1] [INFO] Using worker: uvicorn.workers.UvicornWorker\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:41 +0000] [372] [INFO] Booting worker with pid: 372\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] ENV: environ({'SERVICE_SERVICE_HOST': '10.97.98.126', 'NVIDIA_VISIBLE_DEVICES': 'GPU-aff4abf4-c4ad-fb72-52dd-3fbbbfcb20e0', 'KUBERNETES_SERVICE_PORT_HTTPS': '443', 'GCC_RANLIB': '/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ranlib', 'KUBERNETES_SERVICE_PORT': '443', 'ENV_NAME': 'base', 'build_alias': 'x86_64-conda-linux-gnu', 'CMAKE_ARGS': '-DCMAKE_AR=/opt/conda/bin/x86_64-conda-linux-gnu-ar -DCMAKE_CXX_COMPILER_AR=/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ar -DCMAKE_C_COMPILER_AR=/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ar -DCMAKE_RANLIB=/opt/conda/bin/x86_64-conda-linux-gnu-ranlib -DCMAKE_CXX_COMPILER_RANLIB=/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ranlib -DCMAKE_C_COMPILER_RANLIB=/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ranlib -DCMAKE_LINKER=/opt/conda/bin/x86_64-conda-linux-gnu-ld -DCMAKE_STRIP=/opt/conda/bin/x86_64-conda-linux-gnu-strip -DCMAKE_BUILD_TYPE=Release', 'MAMBA_USER': 'mambauser', 'SERVICE_PORT_5000_TCP_PROTO': 'tcp', 'HOSTNAME': 'statefulset-0', '_CONCURRENT_REQUESTS_MAX': '1', 'GPROF': '/opt/conda/bin/x86_64-conda-linux-gnu-gprof', 'stage_uid': '1000', 'CONDA_TOOLCHAIN_BUILD': 'x86_64-conda-linux-gnu', '_CONDA_PYTHON_SYSCONFIGDATA_NAME': '_sysconfigdata_x86_64_conda_cos6_linux_gnu', 'STRINGS': '/opt/conda/bin/x86_64-conda-linux-gnu-strings', 'CPP': '/opt/conda/bin/x86_64-conda-linux-gnu-cpp', 'NUM_WORKERS': '1', 'SNOWFLAKE_PORT': '443', 'PWD': '/tmp', 'CONDA_PREFIX': '/opt/conda', 'SERVICE_SERVICE_PORT_PREDICT': '5000', 'MAMBA_ROOT_PREFIX': '/opt/conda', 'SNOWFLAKE_ACCOUNT': 'KEB85413', 'SNOWFLAKE_DATABASE': 'DB_USER0007', 'TARGET_METHOD': 'infer', 'CXX': '/opt/conda/bin/x86_64-conda-linux-gnu-c++', 'CXXFLAGS': '-fvisibility-inlines-hidden -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /opt/conda/include', 'CONDA_TOOLCHAIN_HOST': 'x86_64-conda-linux-gnu', 'DEBUG_CXXFLAGS': '-fvisibility-inlines-hidden -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /opt/conda/include', 'vol1_gid': '0', 'vol1_uid': '0', 'LDFLAGS': '-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib', 'HOME': '/home/mambauser', 'SERVICE_PORT_5000_TCP_ADDR': '10.97.98.126', 'LANG': 'C.UTF-8', 'MESON_ARGS': '--buildtype release', 'KUBERNETES_PORT_443_TCP': 'tcp://10.96.0.1:443', 'DEBUG_CFLAGS': '-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /opt/conda/include', 'CXX_FOR_BUILD': '/opt/conda/bin/x86_64-conda-linux-gnu-c++', 'ELFEDIT': '/opt/conda/bin/x86_64-conda-linux-gnu-elfedit', 'CONDA_PROMPT_MODIFIER': '(base) ', 'CMAKE_PREFIX_PATH': '/opt/conda:/opt/conda/x86_64-conda-linux-gnu/sysroot/usr', 'CPPFLAGS': '-DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /opt/conda/include', 'LD': '/opt/conda/bin/x86_64-conda-linux-gnu-ld', 'SNOWML_USE_GPU': 'true', 'SNOWFLAKE_SCHEMA': 'SCHEMA_LLM', 'READELF': '/opt/conda/bin/x86_64-conda-linux-gnu-readelf', 'GXX': '/opt/conda/bin/x86_64-conda-linux-gnu-g++', 'SERVICE_PORT_5000_TCP': 'tcp://10.97.98.126:5000', 'GCC_AR': '/opt/conda/bin/x86_64-conda-linux-gnu-gcc-ar', 'stage_gid': '1000', 'ADDR2LINE': '/opt/conda/bin/x86_64-conda-linux-gnu-addr2line', 'MAMBA_EXE': '/bin/micromamba', 'SNOWFLAKE_HOST': 'snowflake.prod3.us-west-2.aws.snowflakecomputing.com', 'SIZE': '/opt/conda/bin/x86_64-conda-linux-gnu-size', 'GCC_NM': '/opt/conda/bin/x86_64-conda-linux-gnu-gcc-nm', 'HOST': 'x86_64-conda-linux-gnu', 'CC_FOR_BUILD': '/opt/conda/bin/x86_64-conda-linux-gnu-cc', 'USER': 'mambauser', 'SERVICE_PORT_5000_TCP_PORT': '5000', 'CONDA_SHLVL': '1', 'AR': '/opt/conda/bin/x86_64-conda-linux-gnu-ar', 'AS': '/opt/conda/bin/x86_64-conda-linux-gnu-as', 'DEBUG_CPPFLAGS': '-D_DEBUG -D_FORTIFY_SOURCE=2 -Og -isystem /opt/conda/include', 'host_alias': 'x86_64-conda-linux-gnu', 'SHLVL': '0', 'SERVICE_SERVICE_PORT': '5000', 'NM': '/opt/conda/bin/x86_64-conda-linux-gnu-nm', 'GCC': '/opt/conda/bin/x86_64-conda-linux-gnu-gcc', 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp', 'KUBERNETES_PORT_443_TCP_ADDR': '10.96.0.1', 'LD_GOLD': '/opt/conda/bin/x86_64-conda-linux-gnu-ld.gold', 'CONDA_DEFAULT_ENV': 'base', 'OBJCOPY': '/opt/conda/bin/x86_64-conda-linux-gnu-objcopy', 'SNOWFLAKE_SERVICE_NAME': 'SERVICE_6F58D2DE947F11EEB19FACDE48001122', 'KUBERNETES_SERVICE_HOST': '10.96.0.1', 'LC_ALL': 'C.UTF-8', 'KUBERNETES_PORT': 'tcp://10.96.0.1:443', 'KUBERNETES_PORT_443_TCP_PORT': '443', 'STRIP': '/opt/conda/bin/x86_64-conda-linux-gnu-strip', 'SERVICE_PORT': 'tcp://10.97.98.126:5000', 'OBJDUMP': '/opt/conda/bin/x86_64-conda-linux-gnu-objdump', 'PATH': '/opt/conda/bin:/opt/conda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'CC': '/opt/conda/bin/x86_64-conda-linux-gnu-cc', 'CFLAGS': '-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /opt/conda/include', 'CXXFILT': '/opt/conda/bin/x86_64-conda-linux-gnu-c++filt', 'BUILD': 'x86_64-conda-linux-gnu', 'MODEL_ZIP_STAGE_PATH': '/DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_6F58D2DE947F11EEB19FACDE48001122/model.zip', 'RANLIB': '/opt/conda/bin/x86_64-conda-linux-gnu-ranlib', 'CONDA_BUILD_SYSROOT': '/opt/conda/x86_64-conda-linux-gnu/sysroot', 'SERVER_SOFTWARE': 'gunicorn/21.2.0'})\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] Started server process [372]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] Waiting for application startup.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] Application startup complete.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] Extracting model zip from /DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_6F58D2DE947F11EEB19FACDE48001122/model.zip to /tmp/tmpcoomrv8_/extracted_model_dir\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 21:59:42 +0000] [372] [INFO] Loading model from /tmp/tmpcoomrv8_/extracted_model_dir into memory\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:/tmp/tmpcoomrv8_/extracted_model_dir/code/snowflake/ml/model/_packager/model_env/model_env.py:353: UserWarning: Found dependencies specified as pip requirements. This may prevent model deploying to Snowflake Warehouse.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  warnings.warn(\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:There's total 1 GPUs visible to use.\n",
      "Downloading tokenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 546kB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 7.92MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 439kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 37.4MB/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Using pad_token, but it is not set yet.\n",
      "Downloading config.json: 100%|██████████| 614/614 [00:00<00:00, 682kB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 30.3MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 10.5M/9.98G [00:00<03:11, 51.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 41.9M/9.98G [00:00<01:09, 143MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 73.4M/9.98G [00:00<00:52, 188MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 105M/9.98G [00:00<00:47, 209MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 136M/9.98G [00:00<00:41, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 168M/9.98G [00:00<00:42, 232MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 199M/9.98G [00:00<00:40, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 231M/9.98G [00:01<00:38, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 262M/9.98G [00:01<00:36, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 294M/9.98G [00:01<00:35, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 325M/9.98G [00:01<00:36, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 357M/9.98G [00:01<00:36, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 388M/9.98G [00:01<00:36, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 419M/9.98G [00:01<00:36, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 451M/9.98G [00:01<00:37, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 482M/9.98G [00:02<00:36, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 514M/9.98G [00:02<00:36, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 545M/9.98G [00:02<00:36, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 577M/9.98G [00:02<00:35, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 608M/9.98G [00:02<00:34, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 640M/9.98G [00:02<00:33, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 671M/9.98G [00:02<00:32, 284MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 703M/9.98G [00:02<00:32, 286MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 734M/9.98G [00:02<00:33, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 765M/9.98G [00:03<00:33, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 797M/9.98G [00:03<00:34, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 828M/9.98G [00:03<00:35, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 860M/9.98G [00:03<00:35, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 891M/9.98G [00:03<00:35, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 923M/9.98G [00:03<00:35, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 954M/9.98G [00:03<00:34, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 986M/9.98G [00:03<00:33, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.02G/9.98G [00:04<00:33, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.05G/9.98G [00:04<00:33, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.08G/9.98G [00:04<00:33, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.11G/9.98G [00:04<00:33, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 1.14G/9.98G [00:04<00:33, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.17G/9.98G [00:04<00:33, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.21G/9.98G [00:04<00:33, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:04<00:33, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.27G/9.98G [00:04<00:33, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.30G/9.98G [00:05<00:32, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.33G/9.98G [00:05<00:31, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▎        | 1.36G/9.98G [00:05<00:31, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.39G/9.98G [00:05<00:31, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.43G/9.98G [00:05<00:30, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.46G/9.98G [00:05<00:30, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.49G/9.98G [00:05<00:30, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.52G/9.98G [00:05<00:30, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.55G/9.98G [00:05<00:30, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.58G/9.98G [00:06<00:30, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.61G/9.98G [00:06<00:31, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.65G/9.98G [00:06<00:29, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.68G/9.98G [00:06<00:30, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.71G/9.98G [00:06<00:30, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.74G/9.98G [00:06<00:30, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.77G/9.98G [00:06<00:30, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.80G/9.98G [00:06<00:29, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.84G/9.98G [00:07<00:29, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 1.87G/9.98G [00:07<00:29, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.90G/9.98G [00:07<00:29, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.93G/9.98G [00:07<00:29, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.96G/9.98G [00:07<00:29, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.99G/9.98G [00:07<00:29, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.02G/9.98G [00:07<00:29, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.06G/9.98G [00:07<00:30, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.09G/9.98G [00:07<00:29, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.12G/9.98G [00:08<00:31, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.15G/9.98G [00:08<00:30, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.18G/9.98G [00:08<00:30, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.21G/9.98G [00:08<00:30, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.24G/9.98G [00:08<00:30, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.28G/9.98G [00:08<00:29, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.31G/9.98G [00:08<00:32, 239MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.34G/9.98G [00:08<00:31, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.37G/9.98G [00:09<00:31, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.40G/9.98G [00:09<00:30, 247MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.46G/9.98G [00:10<01:45, 71.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.49G/9.98G [00:10<01:45, 71.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:11<02:17, 54.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.53G/9.98G [00:12<02:46, 44.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.56G/9.98G [00:12<01:56, 63.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.59G/9.98G [00:12<01:27, 84.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.62G/9.98G [00:12<01:18, 94.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.64G/9.98G [00:12<01:07, 108MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.67G/9.98G [00:13<01:00, 121MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.69G/9.98G [00:13<01:26, 84.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.72G/9.98G [00:13<01:14, 96.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.75G/9.98G [00:13<00:59, 122MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.78G/9.98G [00:13<00:49, 147MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.81G/9.98G [00:14<00:42, 168MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.84G/9.98G [00:14<00:37, 190MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.87G/9.98G [00:14<00:34, 204MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.90G/9.98G [00:14<00:32, 215MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.94G/9.98G [00:14<00:30, 233MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.97G/9.98G [00:14<00:29, 239MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.00G/9.98G [00:14<00:28, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.03G/9.98G [00:14<00:28, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.06G/9.98G [00:14<00:27, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.09G/9.98G [00:15<00:26, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 3.12G/9.98G [00:15<00:25, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.16G/9.98G [00:15<00:24, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.19G/9.98G [00:15<00:24, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.22G/9.98G [00:15<00:24, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.25G/9.98G [00:15<00:24, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.28G/9.98G [00:15<00:25, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.31G/9.98G [00:15<00:25, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.34G/9.98G [00:16<00:25, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.38G/9.98G [00:16<00:25, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.41G/9.98G [00:16<00:24, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.44G/9.98G [00:16<00:24, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.47G/9.98G [00:16<00:24, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.50G/9.98G [00:16<00:24, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.53G/9.98G [00:16<00:24, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.57G/9.98G [00:16<00:23, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.60G/9.98G [00:16<00:22, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.63G/9.98G [00:17<00:23, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.66G/9.98G [00:17<00:23, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.69G/9.98G [00:17<00:24, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.72G/9.98G [00:17<00:24, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.75G/9.98G [00:17<00:24, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.79G/9.98G [00:17<00:24, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.82G/9.98G [00:17<00:24, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.85G/9.98G [00:17<00:24, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.88G/9.98G [00:18<00:25, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.91G/9.98G [00:18<00:25, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.94G/9.98G [00:18<00:23, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.97G/9.98G [00:18<00:24, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.01G/9.98G [00:18<00:24, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.04G/9.98G [00:18<00:24, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.07G/9.98G [00:18<00:24, 242MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.10G/9.98G [00:19<00:23, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 4.13G/9.98G [00:19<00:23, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.16G/9.98G [00:19<00:23, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.19G/9.98G [00:19<00:23, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.23G/9.98G [00:19<00:22, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.26G/9.98G [00:19<00:22, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.29G/9.98G [00:19<00:21, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.32G/9.98G [00:19<00:21, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.35G/9.98G [00:19<00:20, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.38G/9.98G [00:20<00:20, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.41G/9.98G [00:20<00:20, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.45G/9.98G [00:20<00:21, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.48G/9.98G [00:20<00:21, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.51G/9.98G [00:20<00:20, 260MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.57G/9.98G [00:20<00:21, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.60G/9.98G [00:20<00:21, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▋     | 4.63G/9.98G [00:21<00:20, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.67G/9.98G [00:21<00:20, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.70G/9.98G [00:21<00:19, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.73G/9.98G [00:21<00:19, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.76G/9.98G [00:21<00:20, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.79G/9.98G [00:21<00:21, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.82G/9.98G [00:21<00:20, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 4.85G/9.98G [00:21<00:20, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.89G/9.98G [00:22<00:20, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.92G/9.98G [00:22<00:19, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.95G/9.98G [00:22<00:20, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.98G/9.98G [00:22<00:19, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.01G/9.98G [00:22<00:19, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.04G/9.98G [00:22<00:18, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.08G/9.98G [00:22<00:18, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.11G/9.98G [00:22<00:18, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.14G/9.98G [00:23<00:18, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [00:23<00:18, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.20G/9.98G [00:23<00:18, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.23G/9.98G [00:23<00:18, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.26G/9.98G [00:23<00:18, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.30G/9.98G [00:23<00:18, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.33G/9.98G [00:23<00:18, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.36G/9.98G [00:23<00:18, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.39G/9.98G [00:24<00:20, 224MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.42G/9.98G [00:24<00:29, 156MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.44G/9.98G [00:24<00:27, 165MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.47G/9.98G [00:24<00:23, 189MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.51G/9.98G [00:24<00:21, 205MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.54G/9.98G [00:24<00:20, 218MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.57G/9.98G [00:25<00:19, 229MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.60G/9.98G [00:25<00:18, 242MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.63G/9.98G [00:25<00:17, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.66G/9.98G [00:25<00:16, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.69G/9.98G [00:25<00:16, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.73G/9.98G [00:25<00:15, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.76G/9.98G [00:25<00:16, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.79G/9.98G [00:25<00:16, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.82G/9.98G [00:25<00:15, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.85G/9.98G [00:26<00:15, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.88G/9.98G [00:26<00:15, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.91G/9.98G [00:26<00:15, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.95G/9.98G [00:26<00:15, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.98G/9.98G [00:26<00:15, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.01G/9.98G [00:26<00:15, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.04G/9.98G [00:26<00:15, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.07G/9.98G [00:26<00:15, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.10G/9.98G [00:27<00:14, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.13G/9.98G [00:27<00:14, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.17G/9.98G [00:27<00:14, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.20G/9.98G [00:27<00:14, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.23G/9.98G [00:27<00:14, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.26G/9.98G [00:27<00:14, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.29G/9.98G [00:27<00:13, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.32G/9.98G [00:27<00:13, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.35G/9.98G [00:28<00:13, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [00:28<00:13, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.42G/9.98G [00:28<00:15, 224MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.45G/9.98G [00:28<00:14, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [00:28<00:14, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.51G/9.98G [00:28<00:14, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.54G/9.98G [00:28<00:14, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.57G/9.98G [00:28<00:14, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.61G/9.98G [00:29<00:13, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.64G/9.98G [00:29<00:13, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.67G/9.98G [00:29<00:13, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.70G/9.98G [00:29<00:13, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.73G/9.98G [00:29<00:12, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.76G/9.98G [00:29<00:12, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.79G/9.98G [00:29<00:12, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.83G/9.98G [00:29<00:11, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.86G/9.98G [00:30<00:11, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.89G/9.98G [00:30<00:11, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.92G/9.98G [00:30<00:11, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.95G/9.98G [00:30<00:11, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.98G/9.98G [00:30<00:11, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.01G/9.98G [00:30<00:10, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.05G/9.98G [00:30<00:10, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.08G/9.98G [00:30<00:10, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.11G/9.98G [00:30<00:10, 264MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.17G/9.98G [00:31<00:10, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.20G/9.98G [00:31<00:10, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.24G/9.98G [00:31<00:09, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.27G/9.98G [00:31<00:10, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.30G/9.98G [00:31<00:10, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.33G/9.98G [00:31<00:09, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [00:31<00:09, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [00:32<00:09, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.42G/9.98G [00:32<00:09, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.46G/9.98G [00:32<00:09, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.49G/9.98G [00:32<00:10, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.52G/9.98G [00:32<00:12, 201MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.55G/9.98G [00:32<00:13, 180MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [00:32<00:14, 168MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.59G/9.98G [00:33<00:14, 162MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.61G/9.98G [00:33<00:15, 157MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [00:33<00:15, 156MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.65G/9.98G [00:33<00:15, 152MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.68G/9.98G [00:33<00:15, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [00:33<00:15, 150MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.72G/9.98G [00:34<00:15, 146MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.74G/9.98G [00:34<00:15, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [00:34<00:15, 146MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.78G/9.98G [00:34<00:15, 145MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.80G/9.98G [00:34<00:21, 101MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.83G/9.98G [00:34<00:15, 134MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.86G/9.98G [00:35<00:13, 162MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.89G/9.98G [00:35<00:13, 160MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.91G/9.98G [00:35<00:13, 158MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.93G/9.98G [00:35<00:13, 152MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.95G/9.98G [00:35<00:13, 151MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.97G/9.98G [00:35<00:13, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 7.99G/9.98G [00:35<00:13, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.01G/9.98G [00:36<00:13, 145MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.03G/9.98G [00:36<00:13, 147MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.05G/9.98G [00:36<00:16, 120MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.07G/9.98G [00:36<00:18, 102MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.10G/9.98G [00:37<00:21, 89.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.11G/9.98G [00:37<00:22, 84.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.12G/9.98G [00:37<00:23, 78.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.13G/9.98G [00:37<00:27, 66.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [00:37<00:32, 56.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.15G/9.98G [00:38<00:42, 43.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.16G/9.98G [00:38<00:42, 42.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.19G/9.98G [00:38<00:23, 76.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.22G/9.98G [00:38<00:15, 110MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.25G/9.98G [00:38<00:12, 142MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.28G/9.98G [00:39<00:10, 168MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.32G/9.98G [00:39<00:08, 189MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.35G/9.98G [00:39<00:07, 210MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.38G/9.98G [00:39<00:07, 226MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [00:39<00:06, 233MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.44G/9.98G [00:39<00:06, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [00:39<00:05, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.50G/9.98G [00:39<00:05, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [00:39<00:05, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.57G/9.98G [00:40<00:05, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [00:40<00:05, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.63G/9.98G [00:40<00:05, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.66G/9.98G [00:40<00:04, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.69G/9.98G [00:40<00:04, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.72G/9.98G [00:40<00:04, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.76G/9.98G [00:40<00:04, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.79G/9.98G [00:40<00:04, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.82G/9.98G [00:41<00:04, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.85G/9.98G [00:41<00:04, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.88G/9.98G [00:41<00:04, 272MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.94G/9.98G [00:41<00:03, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.98G/9.98G [00:41<00:03, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.01G/9.98G [00:41<00:03, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.04G/9.98G [00:41<00:03, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.07G/9.98G [00:41<00:03, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.10G/9.98G [00:42<00:03, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.13G/9.98G [00:42<00:03, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.16G/9.98G [00:42<00:03, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.20G/9.98G [00:42<00:03, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.23G/9.98G [00:42<00:03, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.27G/9.98G [00:42<00:02, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.30G/9.98G [00:42<00:02, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.33G/9.98G [00:42<00:02, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.36G/9.98G [00:43<00:02, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.40G/9.98G [00:43<00:02, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [00:43<00:02, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.46G/9.98G [00:43<00:01, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.49G/9.98G [00:43<00:01, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.52G/9.98G [00:43<00:01, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.55G/9.98G [00:43<00:01, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.58G/9.98G [00:43<00:01, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.62G/9.98G [00:44<00:01, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.65G/9.98G [00:44<00:01, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.68G/9.98G [00:44<00:01, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.71G/9.98G [00:44<00:01, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.74G/9.98G [00:44<00:00, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.77G/9.98G [00:44<00:00, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.80G/9.98G [00:44<00:00, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.84G/9.98G [00:44<00:00, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.87G/9.98G [00:45<00:00, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.90G/9.98G [00:45<00:00, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.93G/9.98G [00:45<00:00, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:45<00:00, 219MB/s]\u001b[A\n",
      "Downloading shards:  50%|█████     | 1/2 [00:45<00:45, 45.58s/it]\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 31.5M/3.50G [00:00<00:14, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 62.9M/3.50G [00:00<00:13, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 94.4M/3.50G [00:00<00:13, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 126M/3.50G [00:00<00:13, 256MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 157M/3.50G [00:00<00:12, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 189M/3.50G [00:00<00:12, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 220M/3.50G [00:00<00:12, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 252M/3.50G [00:00<00:12, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 283M/3.50G [00:01<00:12, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 315M/3.50G [00:01<00:18, 174MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 336M/3.50G [00:01<00:21, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 357M/3.50G [00:01<00:23, 131MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 377M/3.50G [00:02<00:25, 122MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 398M/3.50G [00:02<00:26, 117MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 419M/3.50G [00:02<00:27, 111MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 440M/3.50G [00:02<00:36, 84.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 451M/3.50G [00:03<00:39, 77.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 461M/3.50G [00:03<00:42, 70.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 472M/3.50G [00:03<00:48, 62.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 482M/3.50G [00:03<00:59, 50.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 493M/3.50G [00:04<01:14, 40.6MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 514M/3.50G [00:06<03:25, 14.6MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 524M/3.50G [00:09<06:28, 7.65MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 535M/3.50G [00:13<09:14, 5.35MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 566M/3.50G [00:13<04:16, 11.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 598M/3.50G [00:13<02:27, 19.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 629M/3.50G [00:13<01:33, 30.6MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 661M/3.50G [00:13<01:04, 44.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 692M/3.50G [00:13<00:46, 61.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 724M/3.50G [00:13<00:34, 80.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 755M/3.50G [00:14<00:26, 102MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 786M/3.50G [00:14<00:21, 124MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 818M/3.50G [00:14<00:18, 145MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 849M/3.50G [00:14<00:16, 164MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 881M/3.50G [00:14<00:14, 179MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 912M/3.50G [00:14<00:13, 192MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 944M/3.50G [00:14<00:12, 204MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 975M/3.50G [00:14<00:11, 212MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 1.01G/3.50G [00:15<00:11, 222MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 1.04G/3.50G [00:15<00:11, 223MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 1.07G/3.50G [00:15<00:10, 228MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 1.10G/3.50G [00:15<00:10, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.13G/3.50G [00:15<00:09, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.16G/3.50G [00:15<00:09, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.20G/3.50G [00:15<00:09, 242MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 1.23G/3.50G [00:16<00:09, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.26G/3.50G [00:16<00:09, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 1.29G/3.50G [00:16<00:09, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 1.32G/3.50G [00:16<00:09, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 1.35G/3.50G [00:16<00:08, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 1.38G/3.50G [00:16<00:08, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 1.39G/3.50G [01:00<00:08, 247MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 1.42G/3.50G [01:00<14:10, 2.45MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 1.45G/3.50G [01:01<08:51, 3.86MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [01:01<05:45, 5.85MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.51G/3.50G [01:01<03:49, 8.66MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 1.54G/3.50G [01:01<02:36, 12.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 1.57G/3.50G [01:01<01:47, 17.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 1.60G/3.50G [01:01<01:15, 25.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 1.64G/3.50G [01:01<00:53, 34.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [01:01<00:38, 47.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 1.70G/3.50G [01:01<00:28, 62.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [01:02<00:21, 80.6MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 1.76G/3.50G [01:02<00:17, 101MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 1.79G/3.50G [01:02<00:13, 124MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.82G/3.50G [01:02<00:11, 145MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.86G/3.50G [01:02<00:09, 166MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 1.89G/3.50G [01:02<00:08, 186MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.92G/3.50G [01:02<00:07, 201MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 1.95G/3.50G [01:02<00:07, 214MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 1.98G/3.50G [01:03<00:06, 227MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.01G/3.50G [01:03<00:06, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.04G/3.50G [01:03<00:05, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 2.08G/3.50G [01:03<00:05, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 2.11G/3.50G [01:03<00:05, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 2.14G/3.50G [01:03<00:05, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.17G/3.50G [01:03<00:05, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [01:03<00:05, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.23G/3.50G [01:04<00:04, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [01:04<00:04, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.30G/3.50G [01:04<00:04, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [01:04<00:04, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.36G/3.50G [01:04<00:04, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [01:04<00:04, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.42G/3.50G [01:04<00:04, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 2.45G/3.50G [01:04<00:03, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 2.49G/3.50G [01:05<00:03, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [01:05<00:03, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.55G/3.50G [01:05<00:03, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [01:05<00:03, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.61G/3.50G [01:05<00:03, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [01:05<00:03, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 2.67G/3.50G [01:05<00:03, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [01:05<00:02, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.74G/3.50G [01:05<00:02, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [01:06<00:02, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 2.80G/3.50G [01:06<00:02, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 2.83G/3.50G [01:06<00:02, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.86G/3.50G [01:06<00:02, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.89G/3.50G [01:06<00:02, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 2.93G/3.50G [01:06<00:02, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.96G/3.50G [01:06<00:02, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 2.99G/3.50G [01:06<00:01, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 3.02G/3.50G [01:07<00:01, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.05G/3.50G [01:07<00:01, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.08G/3.50G [01:07<00:01, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.11G/3.50G [01:07<00:01, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 3.15G/3.50G [01:07<00:01, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 3.18G/3.50G [01:07<00:01, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.21G/3.50G [01:07<00:01, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.24G/3.50G [01:07<00:01, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.27G/3.50G [01:08<00:00, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.30G/3.50G [01:08<00:00, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 3.33G/3.50G [01:08<00:00, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.37G/3.50G [01:08<00:00, 231MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.40G/3.50G [01:08<00:00, 215MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [01:08<00:00, 224MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.46G/3.50G [01:08<00:00, 232MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [01:09<00:00, 50.7MB/s][A\n",
      "Downloading shards: 100%|██████████| 2/2 [01:54<00:00, 57.36s/it]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:/opt/conda/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  warnings.warn(\n",
      "Downloading generation_config.json: 100%|██████████| 188/188 [00:00<00:00, 74.3kB/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Torch VRAM 0.0 MB allocated.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Torch VRAM 0.0 MB reserved.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:INFO 12-06 22:04:53 llm_engine.py:72] Initializing an LLM engine with config: model='/tmp/tmpnlrboxoo', tokenizer='/tmp/tmpnlrboxoo', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2023-12-06 22:06:53 +0000] [372] [INFO] Successfully loaded model into memory\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Service DB_USER0007.SCHEMA_LLM.service_6f58d2de947f11eeb19facde48001122 is ready. Creating service function...\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Service function DB_USER0007.SCHEMA_LLM.llama_predict is created. Deployment completed successfully!\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_DEPLOYMENTS ( CREATION_TIME,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VI...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EV...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_MODELS_VI...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.19 s, sys: 1.08 s, total: 6.27 s\n",
      "Wall time: 30min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.registry.model_registry.ModelReference at 0x7f8923a88490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Optionally enable INFO log level\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=\"llama_predict\", \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": COMPUTE_POOL, \"num_gpus\": 1})\n",
    "\n",
    "llama_model_ref = model_registry.ModelReference(registry=registry,model_name=MODEL_NAME,model_version=MODEL_VERSION)\n",
    "llama_model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from JSON into Snowflake\n",
    "\n",
    "*NOTE: Reading data in JSON and storing it in a Snowflake table are one time operations. Once the data is loaded, use Snowpark to load the data from the existing table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP STAGE /* Python:snowflake.connector.pandas_tools.write_pandas() */ v...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [PUT /* Python:snowflake.connector.pandas_tools.write_pandas() */ 'file:///var/fo...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP FILE FORMAT lzvkgsetzf /* Python:snowflake.connector.pandas_tools.wr...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT COLUMN_NAME, TYPE FROM table(infer_schema(location=>'@vmnvyhiwkd', file_f...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 6\n",
      "INFO:snowflake.connector.cursor:query: [CREATE  TABLE IF NOT EXISTS pklwlbdfos (LANGUAGE TEXT, TRANSCRIPT TEXT, NAME TEX...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [COPY INTO pklwlbdfos /* Python:snowflake.connector.pandas_tools.write_pandas() *...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DROP TABLE IF EXISTS frosty_transcripts /* Python:snowflake.connector.pandas_too...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [ALTER TABLE pklwlbdfos RENAME TO frosty_transcripts /* Python:snowflake.connecto...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (frosty_transcripts)]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>TRANSCRIPT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>TOY_LIST</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>[\\n  \"Barbie Science Lab Playset\"\\n]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[\\n  \"Barbie Dreamhouse 2023\"\\n]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>[\\n  \"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"\\n]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!</td>\n",
       "      <td>Karen</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>[\\n  \"Orijin Bees Lovey Coiley Baby Bee\"\\n]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>[\\n  \"Gabbys Dollhouse Cruise Ship\"\\n]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LANGUAGE  \\\n",
       "0       EN   \n",
       "1       EN   \n",
       "2       EN   \n",
       "3       EN   \n",
       "4       EN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TRANSCRIPT  \\\n",
       "0  caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "1                                                                                                                                                 caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "2                                                                                                                                                                                                                                                                                                                               caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "3                                                                                                                                                                                                                                                                                                                                      caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!   \n",
       "\n",
       "      NAME     LOCATION  \\\n",
       "0   Rachel       Sydney   \n",
       "1  Jessica  Los Angeles   \n",
       "2   Ashley     Auckland   \n",
       "3    Karen    Vancouver   \n",
       "4    Sarah     Brisbane   \n",
       "\n",
       "                                                                        TOY_LIST  \\\n",
       "0                                           [\\n  \"Barbie Science Lab Playset\"\\n]   \n",
       "1                                               [\\n  \"Barbie Dreamhouse 2023\"\\n]   \n",
       "2  [\\n  \"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"\\n]   \n",
       "3                                    [\\n  \"Orijin Bees Lovey Coiley Baby Bee\"\\n]   \n",
       "4                                         [\\n  \"Gabbys Dollhouse Cruise Ship\"\\n]   \n",
       "\n",
       "   ID  \n",
       "0   0  \n",
       "1   2  \n",
       "2   4  \n",
       "3   5  \n",
       "4   6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/frosty_transcripts.json\",lines=True)\n",
    "sf_df = session.write_pandas(df,'frosty_transcripts',auto_create_table=True,quote_identifiers=False,overwrite=True)\n",
    "sf_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Engineering Example\n",
    "\n",
    "For every transcript, define summarization instruction for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM frosty_transcripts]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT concat_ws(' ', '\\n[INST] Summarize this transcript in less than 200 words...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input\n",
       "0  \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "1                                                                                                                                                 \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "2                                                                                                                                                                                                                                                                                                                               \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "3                                                                                                                                                                                                                                                                                                                                      \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Summarize this transcript in less than 200 words: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_inputs.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using Simple Prompt\n",
    "\n",
    "Pass the summariation instruction to the LLM and examine results of 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelReference.predict() is in private preview since 0.2.0. Do not use it in production. \n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DB_USER0007.SCHEMA_LLM]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "WARNING:snowflake.snowpark:ModelRegistry.get_deployment() is in private preview since 1.0.1. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.list_deployments() is in private preview since 1.0.1. Do not use it in production. \n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_DEPLOYMENTS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT \"MODEL_NAME\", \"MODEL_VERSION...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"MODEL_NAME\", \"MODEL_VERSION\", \"DEPLOYMENT_NAME\", \"CREATION_TIME\", \"TARGE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT concat_ws(' ', '\\n[INST] Summarize this transcript in less than 200 words...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "/Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:310: RuntimeWarning: Warn in feature input: Nullable column \"input\" provided, inference might fail if there is null value.\n",
      "  warnings.warn(\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"input\",  CAST (\"TMP_RESULT\"['generated_text'] AS STRING) AS \"generated_t...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Rachel from Sydney calls to submit her holiday wish list to Frosty. She is considering the Barbie Science Lab Playset for her daughter, who loves science and Barbie. Frosty suggests the Beast Lab: Shark Beast Creator as an alternative, but Rachel decides to stick with the original choice. Frosty thanks Rachel and wishes her a great day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Jessica, a caller from Los Angeles, is looking for a toy for her child that promotes imaginative play and creativity. Frosty suggests the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Jessica decides on the Barbie Dreamhouse, and Frosty asks about her favorite holiday memories. Jessica shares a memory of seeing the city's holiday lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Ashley from Auckland called Frosty to find a gift for her nephew, who loves vehicles and action figures. Frosty suggested the Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van, which Ashley added to her wish list. Ashley also shared her own hobby of hiking and exploring nature, which Frosty appreciated. Frosty wished Ashley a happy holiday season and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]</td>\n",
       "      <td>Karen from Vancouver called Frosty to find a gift for her 4-year-old niece, who loves dolls and plush toys. Frosty recommended the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset. Karen chose the baby bee doll, and Frosty shared a holiday memory of visiting a winter festival with ice sculptures and live performances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>A caller named Sarah from Brisbane is looking for a gift for her daughter who loves playing with dolls and animals. Frosty suggests the Gabbys Dollhouse Cruise Ship, which combines both. Sarah adds it to her wish list and Frosty wishes her a happy holiday season.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input  \\\n",
       "0  \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "1                                                                                                                                                 \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "2                                                                                                                                                                                                                                                                                                                               \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "3                                                                                                                                                                                                                                                                                                                                      \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                         generated_text  \n",
       "0                                    Rachel from Sydney calls to submit her holiday wish list to Frosty. She is considering the Barbie Science Lab Playset for her daughter, who loves science and Barbie. Frosty suggests the Beast Lab: Shark Beast Creator as an alternative, but Rachel decides to stick with the original choice. Frosty thanks Rachel and wishes her a great day.  \n",
       "1         Jessica, a caller from Los Angeles, is looking for a toy for her child that promotes imaginative play and creativity. Frosty suggests the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Jessica decides on the Barbie Dreamhouse, and Frosty asks about her favorite holiday memories. Jessica shares a memory of seeing the city's holiday lights  \n",
       "2    Ashley from Auckland called Frosty to find a gift for her nephew, who loves vehicles and action figures. Frosty suggested the Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van, which Ashley added to her wish list. Ashley also shared her own hobby of hiking and exploring nature, which Frosty appreciated. Frosty wished Ashley a happy holiday season and  \n",
       "3          Karen from Vancouver called Frosty to find a gift for her 4-year-old niece, who loves dolls and plush toys. Frosty recommended the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset. Karen chose the baby bee doll, and Frosty shared a holiday memory of visiting a winter festival with ice sculptures and live performances  \n",
       "4                                                                                                               A caller named Sarah from Brisbane is looking for a gift for her daughter who loves playing with dolls and animals. Frosty suggests the Gabbys Dollhouse Cruise Ship, which combines both. Sarah adds it to her wish list and Frosty wishes her a happy holiday season.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.select('\"input\"','\"generated_text\"').limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Prompt Engineering and Inference Example\n",
    "\n",
    "For every transcript, define more specific instruction for the LLM\n",
    "\n",
    "*NOTE: In the results, notice that the output is not consistent across all transcripts. The base model failed to follow the instructions in many of the cases as seen below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM frosty_transcripts]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DB_USER0007.SCHEMA_LLM]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DB_USER0007.SCHEMA_LLM._SYSTEM_REGISTRY_DEPLOYMENTS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT \"MODEL_NAME\", \"MODEL_VERSION...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"MODEL_NAME\", \"MODEL_VERSION\", \"DEPLOYMENT_NAME\", \"CREATION_TIME\", \"TARGE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT concat_ws(' ', '\\n[INST] Extract location and list of toys in JSON format...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "/Users/chris_carlton1/anaconda3/envs/llm-bootcamp/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:310: RuntimeWarning: Warn in feature input: Nullable column \"input\" provided, inference might fail if there is null value.\n",
      "  warnings.warn(\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"input\",  CAST (\"TMP_RESULT\"['generated_text'] AS STRING) AS \"generated_t...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Rachel\",\\n\"location\": \"Sydney\",\\n\"wishList\": [\\n{\\n\"name\": \"Barbie Science Lab Playset\"\\n},\\n{\\n\"name\": \"Beast Lab: Shark Beast Creator\"\\n}\\n]\\n}\\n\\nExplanation:\\n\\n* \"name\": Rachel is the name of the caller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Los Angeles\",\\n\"listOfToys\": [\\n\"Barbie Dreamhouse 2023\",\\n\"Calico Critters Pony's Stylish Hair Salon\"\\n]\\n}\\n\\nExplanation:\\n\\n* \"location\": This field represents the location where the conversation took place, which is Los Angeles in this case.\\n* \"listOfTo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Auckland\",\\n\"listOfToys\": [\\n\"The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\",\\n\"Bluey Convertible and Figures\"\\n]\\n}\\n\\nNote: The \"listOfToys\" is an array of strings, representing the names of the toys mentioned in the conversation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]</td>\n",
       "      <td>Here is the JSON format for the conversation:\\n\\n{\\n\"caller\": {\\n\"name\": \"Karen\",\\n\"location\": \"Vancouver\"\\n},\\n\"frosty\": {\\n\"gift\": {\\n\"name\": \"Orijin Bees Lovey Coiley Baby Bee\",\\n\"location\": \"\"\\n},\\n\"memories\": [\\n{\\n\"name\": \"winter festival\",\\n\"location\": \"\"\\n}\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure, here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Brisbane\",\\n\"listOfToys\": [\\n\"Gabbys Dollhouse Cruise Ship\"\\n]\\n}\\n\\nExplanation:\\n\\n* \"location\": Brisbane - This is the location where the conversation took place.\\n* \"listOfToys\": [Gabbys Dollhouse Cruise Ship] - This is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, Frosty! My name is Tom, and I'm calling from Dublin. I'd like to submit my holiday wish list.\\nfrosty: Hello, Tom! It's great to have you here. What would you like to add to your holiday wish list?\\ncaller: I think the Lego Olivia's Space Set is a good choice for my daughter.\\nfrosty: Lego Friends Olivia's Space Academy is an excellent toy for kids who love space and building. Before we confirm your wish list, would you like to explore another option based on your daughter's interests?\\ncaller: Sure, another option won't hurt.\\nfrosty: How about the Snap Circuits: Junior set? It's a fascinating and educational toy that teaches kids about electricity and circuits while they build exciting projects.\\ncaller: That actually sounds like a better fit for her. Let's go with the Snap Circuits set instead!\\nfrosty: Fantastic! Your wish list now includes the Snap Circuits: Junior set. Can you tell me how you and your family plan to celebrate the holiday season, Tom?\\ncaller: We're planning a family trip to a ski resort where we can enjoy skiing, hot cocoa, and cozy fireside chats.\\nfrosty: That sounds like a perfect holiday celebration! I hope you and your family have a great time, Tom! Goodbye!\\ncaller: Thanks, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Here is the JSON format for the conversation:\\n\\n{\\n\"caller\": {\\n\"name\": \"Tom\",\\n\"location\": \"Dublin\"\\n},\\n\"frosty\": {\\n\"name\": \"Frosty\",\\n\"location\": \"\"\\n},\\n\"wish_list\": [\\n{\\n\"name\": \"Lego Friends Olivia's Space Academy\",\\n\"location\": \"\"\\n},\\n{\\n\"name\": \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hey Frosty, I'm Tina from San Francisco. I want to submit my holiday wish list but I'm still not sure about the toys.\\nfrosty: Hi Tina! No worries, I'm here to help. Let's explore some toy options based on your child's interests. What does your child like?\\ncaller: My child loves music and dancing around the house. We often have mini dance parties together!\\nfrosty: That's adorable! How about the Sesame Street Monster Meditation Elmo? It's a plush toy that introduces the concept of mindfulness and meditation to kids in a fun way, and it can play music for dance parties too!\\ncaller: Oh, that sounds perfect! Let's add the elmo plushie to our list.\\nfrosty: Great choice! The Sesame Street Monster Meditation Elmo is now on your holiday wish list. Can you share your favorite holiday memory with me, Tina?\\ncaller: I remember watching holiday parades with my family and getting so excited about the festivities. It was a special time for all of us.\\nfrosty: What a beautiful memory! I hope you and your family continue to create more special memories during this holiday season. Have a fantastic day, Tina!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"San Francisco\",\\n\"listOfToys\": [\\n\"Sesame Street Monster Meditation Elmo\"\\n]\\n}\\n\\nNote: The \"listOfToys\" field is an array that contains the single toy item \"Sesame Street Monster Meditation Elmo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, I'd like to submit a holiday wish list.\\nfrosty: Hello and welcome! I'd be happy to help you with that. May I have your name, please?\\ncaller: My name is Emma and I'm calling from London.\\nfrosty: Hi Emma! Thanks for sharing your location. What's on your holiday wish list?\\ncaller: I'm not exactly sure yet. I was thinking about either getting the fox plushie or the gabby dollhouse.\\nfrosty: Both are great choices! Why are you interested in these toys? Are they for someone special?\\ncaller: Yes, they would be for my daughter. She loves animals and playhouses.\\nfrosty: Wonderful! What do you and your family plan to do for the holidays?\\ncaller: We will be having a small family gathering with lots of delicious food and games.\\nfrosty: Sounds like a lovely time! How about a favorite pastime or hobby? Anything you particularly enjoy?\\ncaller: I love knitting and my husband enjoys woodworking. We both love creating things with our hands.\\nfrosty: That's excellent! Since your daughter also seems to enjoy creative play, I would suggest the gabby dollhouse. It has multiple levels and rooms for imagination and play. Does that sound good?\\ncaller: Yes, that sounds perfect. Let's add the gabby dollhouse to the holiday wish\\n\\n list.\\nfrosty: Before we wrap up, let's confirm the toy. We have the Gabbys Dollhouse Cruise Ship for the holiday wish list. Is that correct?\\ncaller: Yes, that's it!\\nfrosty: Great, your holiday wish list of Gabbys Dollhouse Cruise Ship is all set, Emma from London! Have a fantastic holiday season and take care!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure, here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Emma\",\\n\"location\": \"London\",\\n\"holiday_wish_list\": [\\n{\\n\"toy\": \"Fox Plushie\",\\n\"reason\": \"for my daughter\"\\n},\\n{\\n\"toy\": \"Gabby Dollhouse\",\\n\"reason\": \"she loves playhouses\"\\n}\\n]\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi, I'd like to submit a holiday wish list for my son. \\nfrosty: Of course! I'd be glad to assist you. May I know your name and location?\\ncaller: I'm Michael from New York City.\\nfrosty: Great, Michael! What toys would you like to add to your holiday wish list?\\ncaller: I'm not sure yet. My son really likes action figures and building sets.\\nfrosty: That helps! How do you and your family plan to celebrate the holiday season?\\ncaller: We usually have a big family dinner and exchange gifts together.\\nfrosty: Lovely! Based on your son's interests, I'd suggest the spiderman playset or the lego olivia's space set. Which one do you think he would like more?\\ncaller: I think he'd really like the spiderman playset.\\nfrosty: Great choice! What do you enjoy the most about this time of the year?\\ncaller: I love spending time with my family and watching my son's excitement when he opens his gifts.\\nfrosty: That's so heartwarming! Before we end the call, let me confirm your holiday wish list. We have Marvel's Spidey and His Amazing Friends Web Spinners playset for your son. Is that correct?\\ncaller: Yes, that's it. Thank you!\\nfrosty: You're welcome, Michael from New York City! Enjoy the holiday season and have a wonderful time with your family!  [/INST]</td>\n",
       "      <td>Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Michael\",\\n\"location\": \"New York City\",\\n\"toys\": [\\n{\\n\"name\": \"Marvel's Spidey and His Amazing Friends Web Spinners playset\"\\n},\\n{\\n\"name\": \"Spiderman playset\"\\n}\\n]\\n}\\n\\nIn this example, the conversation is represented as a JSON object with three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n[INST] Extract location and list of toys in JSON format: \\n caller: Hello!\\nfrosty: Hi there! Welcome to our holiday hotline! How can I help you submit your wish list today?\\ncaller: My name is Sarah, and I'm calling from Sydney. I want to get a toy for my child this holiday season.\\nfrosty: Nice to meet you, Sarah! You've come to the right place. Why don't you tell me about your child's interests, and if you have any specific toys in mind from our list?\\ncaller: My child loves animals. We are thinking of getting the fox plushie.\\nfrosty: The 2023 Holiday Fox 12-Inch Plush is an excellent choice for animal lovers! May I ask why you are interested in this toy for your child?\\ncaller: It reminds my child of our holiday at the countryside where they had a chance to see wild foxes.\\nfrosty: That's a wonderful memory to share! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be having a small family gathering at home with lots of food and fun activities.\\nfrosty: That sounds lovely, Sarah. Do you have any other wish list items, or is the fox plushie the only one you'd like to submit?\\ncaller: Actually, I just remembered my child also mentioned the trasformers bumblebee.\\nfrosty: The Transformers Rise of the Beasts Beast-Mode Bumblebee is a popular choice this year for children who love action figures! Before we finalize your wish list, can you tell me about your favorite holiday memory?\\ncaller: My favorite memory is when we went camping in the mountains during the holidays. We were surrounded by nature and spent quality time together as a family.\\nfrosty: That sounds like a truly memorable experience! So, to confirm, your holiday wish list consists of the fox plushie and trasformers bumblebee. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your wish list has been submitted, Sarah. I hope you and your family have a fantastic holiday season and enjoy the toys!\\ncaller: Thank you so much! Happy holidays!  [/INST]</td>\n",
       "      <td>Sure! Here is the location and list of toys in JSON format based on the conversation:\\n\\n{\\n\"location\": \"Sydney\",\\n\"toys\": [\\n{\\n\"name\": \"2023 Holiday Fox 12-Inch Plush\",\\n\"description\": \"An excellent choice for animal lovers\"\\n},\\n{\\n\"name\": \"Transformers Rise of the Beasts Beast-Mode Bumblebee\",</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      input  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, Frosty! My name is Tom, and I'm calling from Dublin. I'd like to submit my holiday wish list.\\nfrosty: Hello, Tom! It's great to have you here. What would you like to add to your holiday wish list?\\ncaller: I think the Lego Olivia's Space Set is a good choice for my daughter.\\nfrosty: Lego Friends Olivia's Space Academy is an excellent toy for kids who love space and building. Before we confirm your wish list, would you like to explore another option based on your daughter's interests?\\ncaller: Sure, another option won't hurt.\\nfrosty: How about the Snap Circuits: Junior set? It's a fascinating and educational toy that teaches kids about electricity and circuits while they build exciting projects.\\ncaller: That actually sounds like a better fit for her. Let's go with the Snap Circuits set instead!\\nfrosty: Fantastic! Your wish list now includes the Snap Circuits: Junior set. Can you tell me how you and your family plan to celebrate the holiday season, Tom?\\ncaller: We're planning a family trip to a ski resort where we can enjoy skiing, hot cocoa, and cozy fireside chats.\\nfrosty: That sounds like a perfect holiday celebration! I hope you and your family have a great time, Tom! Goodbye!\\ncaller: Thanks, Frosty! Happy holidays!  [/INST]   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hey Frosty, I'm Tina from San Francisco. I want to submit my holiday wish list but I'm still not sure about the toys.\\nfrosty: Hi Tina! No worries, I'm here to help. Let's explore some toy options based on your child's interests. What does your child like?\\ncaller: My child loves music and dancing around the house. We often have mini dance parties together!\\nfrosty: That's adorable! How about the Sesame Street Monster Meditation Elmo? It's a plush toy that introduces the concept of mindfulness and meditation to kids in a fun way, and it can play music for dance parties too!\\ncaller: Oh, that sounds perfect! Let's add the elmo plushie to our list.\\nfrosty: Great choice! The Sesame Street Monster Meditation Elmo is now on your holiday wish list. Can you share your favorite holiday memory with me, Tina?\\ncaller: I remember watching holiday parades with my family and getting so excited about the festivities. It was a special time for all of us.\\nfrosty: What a beautiful memory! I hope you and your family continue to create more special memories during this holiday season. Have a fantastic day, Tina!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]   \n",
       "7                                                                                                                                                                                                                                                                                                                        \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi there, I'd like to submit a holiday wish list.\\nfrosty: Hello and welcome! I'd be happy to help you with that. May I have your name, please?\\ncaller: My name is Emma and I'm calling from London.\\nfrosty: Hi Emma! Thanks for sharing your location. What's on your holiday wish list?\\ncaller: I'm not exactly sure yet. I was thinking about either getting the fox plushie or the gabby dollhouse.\\nfrosty: Both are great choices! Why are you interested in these toys? Are they for someone special?\\ncaller: Yes, they would be for my daughter. She loves animals and playhouses.\\nfrosty: Wonderful! What do you and your family plan to do for the holidays?\\ncaller: We will be having a small family gathering with lots of delicious food and games.\\nfrosty: Sounds like a lovely time! How about a favorite pastime or hobby? Anything you particularly enjoy?\\ncaller: I love knitting and my husband enjoys woodworking. We both love creating things with our hands.\\nfrosty: That's excellent! Since your daughter also seems to enjoy creative play, I would suggest the gabby dollhouse. It has multiple levels and rooms for imagination and play. Does that sound good?\\ncaller: Yes, that sounds perfect. Let's add the gabby dollhouse to the holiday wish\\n\\n list.\\nfrosty: Before we wrap up, let's confirm the toy. We have the Gabbys Dollhouse Cruise Ship for the holiday wish list. Is that correct?\\ncaller: Yes, that's it!\\nfrosty: Great, your holiday wish list of Gabbys Dollhouse Cruise Ship is all set, Emma from London! Have a fantastic holiday season and take care!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hi, I'd like to submit a holiday wish list for my son. \\nfrosty: Of course! I'd be glad to assist you. May I know your name and location?\\ncaller: I'm Michael from New York City.\\nfrosty: Great, Michael! What toys would you like to add to your holiday wish list?\\ncaller: I'm not sure yet. My son really likes action figures and building sets.\\nfrosty: That helps! How do you and your family plan to celebrate the holiday season?\\ncaller: We usually have a big family dinner and exchange gifts together.\\nfrosty: Lovely! Based on your son's interests, I'd suggest the spiderman playset or the lego olivia's space set. Which one do you think he would like more?\\ncaller: I think he'd really like the spiderman playset.\\nfrosty: Great choice! What do you enjoy the most about this time of the year?\\ncaller: I love spending time with my family and watching my son's excitement when he opens his gifts.\\nfrosty: That's so heartwarming! Before we end the call, let me confirm your holiday wish list. We have Marvel's Spidey and His Amazing Friends Web Spinners playset for your son. Is that correct?\\ncaller: Yes, that's it. Thank you!\\nfrosty: You're welcome, Michael from New York City! Enjoy the holiday season and have a wonderful time with your family!  [/INST]   \n",
       "9  \\n[INST] Extract location and list of toys in JSON format: \\n caller: Hello!\\nfrosty: Hi there! Welcome to our holiday hotline! How can I help you submit your wish list today?\\ncaller: My name is Sarah, and I'm calling from Sydney. I want to get a toy for my child this holiday season.\\nfrosty: Nice to meet you, Sarah! You've come to the right place. Why don't you tell me about your child's interests, and if you have any specific toys in mind from our list?\\ncaller: My child loves animals. We are thinking of getting the fox plushie.\\nfrosty: The 2023 Holiday Fox 12-Inch Plush is an excellent choice for animal lovers! May I ask why you are interested in this toy for your child?\\ncaller: It reminds my child of our holiday at the countryside where they had a chance to see wild foxes.\\nfrosty: That's a wonderful memory to share! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be having a small family gathering at home with lots of food and fun activities.\\nfrosty: That sounds lovely, Sarah. Do you have any other wish list items, or is the fox plushie the only one you'd like to submit?\\ncaller: Actually, I just remembered my child also mentioned the trasformers bumblebee.\\nfrosty: The Transformers Rise of the Beasts Beast-Mode Bumblebee is a popular choice this year for children who love action figures! Before we finalize your wish list, can you tell me about your favorite holiday memory?\\ncaller: My favorite memory is when we went camping in the mountains during the holidays. We were surrounded by nature and spent quality time together as a family.\\nfrosty: That sounds like a truly memorable experience! So, to confirm, your holiday wish list consists of the fox plushie and trasformers bumblebee. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your wish list has been submitted, Sarah. I hope you and your family have a fantastic holiday season and enjoy the toys!\\ncaller: Thank you so much! Happy holidays!  [/INST]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                generated_text  \n",
       "0                                                           Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Rachel\",\\n\"location\": \"Sydney\",\\n\"wishList\": [\\n{\\n\"name\": \"Barbie Science Lab Playset\"\\n},\\n{\\n\"name\": \"Beast Lab: Shark Beast Creator\"\\n}\\n]\\n}\\n\\nExplanation:\\n\\n* \"name\": Rachel is the name of the caller  \n",
       "1         Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Los Angeles\",\\n\"listOfToys\": [\\n\"Barbie Dreamhouse 2023\",\\n\"Calico Critters Pony's Stylish Hair Salon\"\\n]\\n}\\n\\nExplanation:\\n\\n* \"location\": This field represents the location where the conversation took place, which is Los Angeles in this case.\\n* \"listOfTo  \n",
       "2    Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Auckland\",\\n\"listOfToys\": [\\n\"The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\",\\n\"Bluey Convertible and Figures\"\\n]\\n}\\n\\nNote: The \"listOfToys\" is an array of strings, representing the names of the toys mentioned in the conversation.  \n",
       "3                                                                  Here is the JSON format for the conversation:\\n\\n{\\n\"caller\": {\\n\"name\": \"Karen\",\\n\"location\": \"Vancouver\"\\n},\\n\"frosty\": {\\n\"gift\": {\\n\"name\": \"Orijin Bees Lovey Coiley Baby Bee\",\\n\"location\": \"\"\\n},\\n\"memories\": [\\n{\\n\"name\": \"winter festival\",\\n\"location\": \"\"\\n}\\n  \n",
       "4                                       Sure, here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"Brisbane\",\\n\"listOfToys\": [\\n\"Gabbys Dollhouse Cruise Ship\"\\n]\\n}\\n\\nExplanation:\\n\\n* \"location\": Brisbane - This is the location where the conversation took place.\\n* \"listOfToys\": [Gabbys Dollhouse Cruise Ship] - This is  \n",
       "5                                                                           Here is the JSON format for the conversation:\\n\\n{\\n\"caller\": {\\n\"name\": \"Tom\",\\n\"location\": \"Dublin\"\\n},\\n\"frosty\": {\\n\"name\": \"Frosty\",\\n\"location\": \"\"\\n},\\n\"wish_list\": [\\n{\\n\"name\": \"Lego Friends Olivia's Space Academy\",\\n\"location\": \"\"\\n},\\n{\\n\"name\": \"  \n",
       "6                                                                Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"location\": \"San Francisco\",\\n\"listOfToys\": [\\n\"Sesame Street Monster Meditation Elmo\"\\n]\\n}\\n\\nNote: The \"listOfToys\" field is an array that contains the single toy item \"Sesame Street Monster Meditation Elmo\".  \n",
       "7                                                                                 Sure, here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Emma\",\\n\"location\": \"London\",\\n\"holiday_wish_list\": [\\n{\\n\"toy\": \"Fox Plushie\",\\n\"reason\": \"for my daughter\"\\n},\\n{\\n\"toy\": \"Gabby Dollhouse\",\\n\"reason\": \"she loves playhouses\"\\n}\\n]\\n}  \n",
       "8                Sure! Here is the JSON format for the conversation:\\n\\n{\\n\"name\": \"Michael\",\\n\"location\": \"New York City\",\\n\"toys\": [\\n{\\n\"name\": \"Marvel's Spidey and His Amazing Friends Web Spinners playset\"\\n},\\n{\\n\"name\": \"Spiderman playset\"\\n}\\n]\\n}\\n\\nIn this example, the conversation is represented as a JSON object with three  \n",
       "9                                   Sure! Here is the location and list of toys in JSON format based on the conversation:\\n\\n{\\n\"location\": \"Sydney\",\\n\"toys\": [\\n{\\n\"name\": \"2023 Holiday Fox 12-Inch Plush\",\\n\"description\": \"An excellent choice for animal lovers\"\\n},\\n{\\n\"name\": \"Transformers Rise of the Beasts Beast-Mode Bumblebee\",  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_df = session.table('frosty_transcripts')\n",
    "\n",
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Extract location and list of toys in JSON format: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2 Preparation\n",
    "\n",
    "Follow the instructions below to prepare your environment for BUILD LLM Bootcamp Day 2. \n",
    "\n",
    "*NOTE:* These operations can take about ~45-60mins depending on your wireless connection.\n",
    "\n",
    "1) Open terminal window and browse to the folder where you have cloned the repository\n",
    "\n",
    "2) Change folder to *day2*\n",
    "\n",
    "3) Run command *`docker build --platform linux/amd64 -t llm-bootcamp .`*\n",
    "\n",
    "4) Once that image is built locally, run the following commands to push the image to Snowflake Registry\n",
    "\n",
    "    1) Replace ***your-account-name*** with your account name and ***your-db-name*** with the name of your database ***in lowercase*** and then run the following command\n",
    "\n",
    "        `docker tag llm-bootcamp:latest sfsenorthamerica-your-account-name.registry.snowflakecomputing.com/your-db-name/schema_llm/image_repo/llm-bootcamp:latest`\n",
    "\n",
    "    2) Replace ***your-account-name*** with your account name and run the following command to login using your LLM Bootcamp Snowflake account username and password\n",
    "\n",
    "        `docker login sfsenorthamerica-your-account-name.registry.snowflakecomputing.com`\n",
    "        \n",
    "    3) Replace ***your-account-name*** with your account name and ***your-db-name*** with the name of your database ***in lowercase*** and then run the following command\n",
    "    \n",
    "        `docker push sfsenorthamerica-your-account-name.registry.snowflakecomputing.com/your-db-name/schema_llm/image_repo/llm-bootcamp:latest`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
